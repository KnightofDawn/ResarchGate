{"cited_in": [], "datas": {"publication_uid": "283761954", "title": "Visual7W: Grounded Question Answering in Images", "authors": {"1": "Yuke Zhu", "4": "Li Fei-Fei", "3": "Michael Bernstein", "2": "Oliver Groth"}, "abstract": "  ABSTRACT We have seen great progress in basic perceptual tasks such as object recognition and detection. However, AI models still fail to match humans in high-level vision tasks due to the lack of capacities for deeper reasoning. Recently the new task of visual question answering (QA) has been proposed to evaluate a model's capacity for deep image understanding. Previous works have established a loose, global association between QA sentences and images. However, many questions and answers, in practice, relate to local regions in the images. We establish a semantic link between textual descriptions and image regions by object-level grounding. It enables a new type of QA with visual answers, in addition to textual answers used in previous work. We study the visual QA tasks in a grounded setting with a large collection of 7W multiple-choice QA pairs. Furthermore, we evaluate human performance and several baseline models on the QA tasks. Finally, we propose a novel LSTM model with spatial attention to tackle the 7W QA tasks.  "}, "references": ["https://www.researchgate.net/publication/220877439_VizWiz_Nearly_Real-time_Answers_to_Visual_Questions", "https://www.researchgate.net/publication/268524772_Learning_a_Recurrent_Visual_Representation_for_Image_Caption_Generation", "https://www.researchgate.net/publication/268525836_Long-term_Recurrent_Convolutional_Networks_for_Visual_Recognition_and_Description", "https://www.researchgate.net/publication/277023024_Are_You_Talking_to_a_Machine_Dataset_and_Methods_for_Multilingual_Image_Question_Answering", "https://www.researchgate.net/publication/273387445_Visual_Turing_test_for_computer_vision_systems", "https://www.researchgate.net/publication/258374356_Rich_Feature_Hierarchies_for_Accurate_Object_Detection_and_Semantic_Segmentation", "https://www.researchgate.net/publication/272422583_DRAW_A_Recurrent_Neural_Network_For_Image_Generation", "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory", "https://www.researchgate.net/publication/269339562_Deep_Visual-Semantic_Alignments_for_Generating_Image_Descriptions", "https://www.researchgate.net/publication/263352571_Deep_Fragment_Embeddings_for_Bidirectional_Image_Sentence_Mapping", "https://www.researchgate.net/publication/264975559_What_are_you_talking_about_Text-to-Image_Coreference", "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks", "https://www.researchgate.net/publication/227943302_Learning_To_Detect_Unseen_Object_Classes_by_Between-Class_Attribute_Transfer", "https://www.researchgate.net/publication/275044474_Learning_Deep_Representations_for_Ground-to-Aerial_Geolocalization", "https://www.researchgate.net/publication/263002356_Microsoft_COCO_Common_Objects_in_Context", "https://www.researchgate.net/publication/277603746_Learning_to_Answer_Questions_From_Image_Using_Convolutional_Neural_Network", "https://www.researchgate.net/publication/266376838_A_Multi-World_Approach_to_Question_Answering_about_Real-World_Scenes_based_on_Uncertain_Input", "https://www.researchgate.net/publication/275974823_Ask_Your_Neurons_A_Neural-based_Approach_to_Answering_Questions_about_Images", "https://www.researchgate.net/publication/257882504_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality", "https://www.researchgate.net/publication/262390837_Dating_Historical_Color_Images", "https://www.researchgate.net/publication/261306213_SUN_attribute_database_Discovering_annotating_and_recognizing_scene_attributes", "https://www.researchgate.net/publication/279840550_Seeing_the_Arrow_of_Time", "https://www.researchgate.net/publication/263316548_Inferring_the_Why_in_Images", "https://www.researchgate.net/publication/277023758_Flickr30k_Entities_Collecting_Region-to-Phrase_Correspondences_for_Richer_Image-to-Sentence_Models", "https://www.researchgate.net/publication/271435947_Translating_Video_Content_to_Natural_Language_Descriptions", "https://www.researchgate.net/publication/265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition", "https://www.researchgate.net/publication/265554383_Sequence_to_Sequence_Learning_with_Neural_Networks", "https://www.researchgate.net/publication/263564119_DeepFace_Closing_the_Gap_to_Human-Level_Performance_in_Face_Verification", "https://www.researchgate.net/publication/259335300_DeepPose_Human_Pose_Estimation_via_Deep_Neural_Networks", "https://www.researchgate.net/publication/256297773_Joint_Video_and_Text_Parsing_for_Understanding_Events_and_Answering_Queries", "https://www.researchgate.net/publication/268451983_Show_and_Tell_A_Neural_Image_Caption_Generator", "https://www.researchgate.net/publication/272522139_Towards_AI-Complete_Question_Answering_A_Set_of_Prerequisite_Toy_Tasks", "https://www.researchgate.net/publication/272194766_Show_Attend_and_Tell_Neural_Image_Caption_Generation_with_Visual_Attention", "https://www.researchgate.net/publication/277603633_Visual_Madlibs_Fill_in_the_blank_Image_Generation_and_Question_Answering", "https://www.researchgate.net/publication/279839496_Learning_Deep_Features_for_Scene_Recognition_using_Places_Database", "https://www.researchgate.net/publication/271551178_Learning_the_Visual_Interpretation_of_Sentences"]}