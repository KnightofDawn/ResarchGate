{"cited_in": [], "datas": {"publication_uid": "279698538", "title": "Recurrent Convolutional Neural Networks for Object-Class Segmentation of RGB-D Video", "authors": {"1": "Mircea Serban Pavel", "3": "Sven Behnke", "2": "Hannes Schulz"}, "abstract": "  ABSTRACT Object-class segmentation is a computer vision task which requires labeling each pixel of an image with the class of the object it belongs to. Deep convolutional neural networks (DNN) are able to learn and exploit local spatial correlations required for this task. They are, however, restricted by their small, fixed-sized filters, which limits their ability to learn long-range dependencies. Recurrent Neural Networks (RNN), on the other hand, do not suffer from this restriction. Their iterative interpretation allows them to model long-range dependencies by propagating activity. This property might be especially useful when labeling video sequences, where both spatial and temporal long-range dependencies occur. In this work, we propose novel RNN architectures for object-class segmentation. We investigate three ways to consider past and future context in the prediction process by comparing networks that process the frames one by one with networks that have access to the whole sequence. We evaluate our models on the challenging NYU Depth v2 dataset for object-class segmentation and obtain competitive results.  "}, "references": ["https://www.researchgate.net/publication/2985446_Gradient-based_learning_applied_to_document_recognition_Proc_IEEE", "https://www.researchgate.net/publication/228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors_arXiv_preprint_arXiv12070580", "https://www.researchgate.net/publication/258818168_Speech_Recognition_with_Deep_Recurrent_Neural_Networks", "https://www.researchgate.net/publication/224254831_Appendix_Learning_Hierarchical_Invariant_Spatio-Temporal_Features_for_Action_Recognition_with_Independent_Subspace_Analysis", "https://www.researchgate.net/publication/216792694_Convolutional_Learning_of_Spatio-temporal_Features", "https://www.researchgate.net/publication/262974436_Two-Stream_Convolutional_Networks_for_Action_Recognition_in_Videos", "https://www.researchgate.net/publication/237145719_Recurrent_Convolutional_Neural_Networks_for_Scene_Parsing", "https://www.researchgate.net/publication/233730646_On_the_difficulty_of_training_Recurrent_Neural_Networks", "https://www.researchgate.net/publication/259334958_Dropout_Improves_Recurrent_Neural_Networks_for_Handwriting_Recognition", "https://www.researchgate.net/publication/262222168_Indoor_Segmentation_and_Support_Inference_from_RGBD_Images", "https://www.researchgate.net/publication/2896183_Colorization_using_Optimization", "https://www.researchgate.net/publication/264435949_Fast_Semantic_Segmentation_of_RGB-D_Scenes_with_GPU-Accelerated_Deep_Neural_Networks", "https://www.researchgate.net/publication/272745291_Depth_and_Height_Aware_Semantic_RGB-D_Perception_with_Convolutional_Neural_Networks", "https://www.researchgate.net/publication/258847801_Dense_Real-Time_Mapping_of_Object-Class_Semantics_from_RGB-D_Video", "https://www.researchgate.net/publication/260206502_Learning_Depth-Sensitive_Conditional_Random_Fields_for_Semantic_Segmentation_of_RGB-D_Images", "https://www.researchgate.net/publication/234131118_Indoor_Semantic_Segmentation_using_depth_information"]}