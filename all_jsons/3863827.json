{"cited_in": ["https://www.researchgate.net/publication/285245147_A_multimodal_framework_for_recognizing_emotional_feedback_in_conversational_recommender_systems", "https://www.researchgate.net/publication/224168305_Audio-visual_Information_Fusion_In_Human_Computer_Interfaces_and_Intelligent_Environments_A_Survey", "https://www.researchgate.net/publication/224149594_Decision_level_combination_of_multiple_modalities_for_recognition_and_analysis_of_emotional_expression", "https://www.researchgate.net/publication/225359641_Towards_Emotion_Recognition_from_Speech_Definition_Problems_and_the_Materials_of_Research", "https://www.researchgate.net/publication/262212706_A_novel_device_for_recognition_of_human_physiological_state", "https://www.researchgate.net/publication/253894432_Multimedia_Information_Extraction_Roadmap_Integration_of_Affective_Computing_and_Multimedia_Information_Extraction", "https://www.researchgate.net/publication/221052254_Detecting_communication_errors_from_visual_cues_during_the_system's_conversational_turn", "https://www.researchgate.net/publication/3424532_Audio-Visual_Affect_Recognition", "https://www.researchgate.net/publication/220931898_Emotion_Recognition_Based_on_Joint_Visual_and_Audio_Cues", "https://www.researchgate.net/publication/221484946_Integrating_information_from_speech_and_physiological_signals_to_achieve_emotional_sensitivity", "https://www.researchgate.net/publication/228823950_Bimodal_Modelling_of_Facial_and_Upper-Body_Gesture_for_Affective_HCI", "https://www.researchgate.net/publication/2986190_Toward_an_affect-sensitive_multimodal_human-computer_interaction", "https://www.researchgate.net/publication/228916445_EMOTIONS_RECOGNITION_BY_SPEECH_AND_FACIAL_EXPRESSIONS_ANALYSIS", "https://www.researchgate.net/publication/228861322_Remarks_on_emotion_recognition_from_bio-potential_signals", "https://www.researchgate.net/publication/225908664_Recognition_of_Emotional_States_in_Natural_Human-Computer_Interaction", "https://www.researchgate.net/publication/221564996_Face_and_Body_Gesture_Recognition_for_a_Vision-Based_Multimodal_Analyzer", "https://www.researchgate.net/publication/277294757_CIRCUIT_C1997_JOHN_FOXX_IMAGES_HEAD_C1995_PHOTODISC_INC", "https://www.researchgate.net/publication/3321450_Brain-Computer_Interface_in_Multimedia_Communication", "https://www.researchgate.net/publication/4043458_Remarks_on_Emotion_Recognition_from_Multi-Modal_Bio-Potential_Signals", "https://www.researchgate.net/publication/221052709_Bimodal_HCI-related_affect_recognition", "https://www.researchgate.net/publication/221052478_Analysis_of_emotion_recognition_using_facial_expressions_speech_and_multimodal_information", "https://www.researchgate.net/publication/221610007_Face_and_Body_Gesture_Analysis_for_Multimodal_HCI", "https://www.researchgate.net/publication/3318793_Constrained_Optimization_for_Audio-to-Visual_Conversion", "https://www.researchgate.net/publication/228616884_Multimodal_emotion_recognition", "https://www.researchgate.net/publication/240954177_Multimodal_approaches_for_emotion_recognition_A_survey", "https://www.researchgate.net/publication/221571403_Affective_multimodal_human-computer_interaction", "https://www.researchgate.net/publication/4163464_Remarks_on_emotion_recognition_from_multi-modal_bio-potential_signals", "https://www.researchgate.net/publication/4156342_Audio-visual_affect_recognition_through_multi-stream_fused_HMM_for_HCI", "https://www.researchgate.net/publication/221652499_Comparison_between_Fuzzy_and_NN_Method_for_Speech_Emotion_Recognition", "https://www.researchgate.net/publication/224621394_VisualAcoustic_Emotion_Recognition", "https://www.researchgate.net/publication/4177577_Fusing_face_and_body_gesture_for_machine_recognition_of_emotions", "https://www.researchgate.net/publication/221622089_Fusing_Face_and_Body_Display_for_Bi-modal_Emotion_Recognition_Single_Frame_Analysis_and_Multi-frame_Post_Integration", "https://www.researchgate.net/publication/221622131_Multi-stream_Confidence_Analysis_for_Audio-Visual_Affect_Recognition", "https://www.researchgate.net/publication/220726852_Emotion_Recognition_Using_Physiological_and_Speech_Signal_in_Short-Term_Observation", "https://www.researchgate.net/publication/220393414_Feature_Selection_in_Audiovisual_Emotion_Recognition_Based_on_Rough_Set_Theory", "https://www.researchgate.net/publication/220955191_Audio-Visual_Spontaneous_Emotion_Recognition", "https://www.researchgate.net/publication/220955197_Modeling_Naturalistic_Affective_States_Via_Facial_Vocal_and_Bodily_Expressions_Recognition", "https://www.researchgate.net/publication/221786570_Bimodal_Emotion_Recognition_using_Speech_and_Physiological_Changes", "https://www.researchgate.net/publication/3424754_Audio-Visual_Affective_Expression_Recognition_Through_Multistream_Fused_HMM", "https://www.researchgate.net/publication/4357136_Hybrid_Petri_Nets_as_a_New_Formalism_for_Modeling_Electrical_Drives", "https://www.researchgate.net/publication/4370913_Towards_end-user_physiological_profiling_for_video_recommendation_engines", "https://www.researchgate.net/publication/221565462_Comparison_Of_Different_Classifiers_for_Emotion_Recognition", "https://www.researchgate.net/publication/251371671_Applications_and_Future_Directions_of_Emotional_Intelligence", "https://www.researchgate.net/publication/232625734_Statistical_Evaluation_of_Speech_Features_for_Emotion_Recognition", "https://www.researchgate.net/publication/258407534_Ethics_and_Policy_of_Biometrics", "https://www.researchgate.net/publication/226433553_Human_Face_Analysis_From_Identity_to_Emotion_and_Intention_Recognition", "https://www.researchgate.net/publication/46179200_Discrete_Wavelet_Transform_Based_Classification_of_Human_Emotions_Using_Electroencephalogram_Signals", "https://www.researchgate.net/publication/269700848_Multi-modal_emotion_recognition_-_more_cognitive_machines", "https://www.researchgate.net/publication/50247425_Comparison_between_k-nn_and_svm_method_for_speech_emotion_recognition", "https://www.researchgate.net/publication/225122788_Biometrics_in_ambient_intelligence", "https://www.researchgate.net/publication/256309236_Multi-Modal_Classifier-Fusion_for_the_Recognition_of_Emotions", "https://www.researchgate.net/publication/262411715_Kindergarten_social_assistive_robot_First_meeting_and_ethical_issues", "https://www.researchgate.net/publication/259127160_Storytelling_by_a_kindergarten_social_assistive_robot_A_tool_for_constructive_learning_in_preschool_education", "https://www.researchgate.net/publication/271916593_Recognizing_signals_of_social_attitude_in_interacting_with_Ambient_Conversational_Systems"], "datas": {"publication_uid": "3863827", "title": "Emotional expressions in audiovisual human computer interaction", "authors": {"1": "Lawrence S. Chen", "2": "Thomas S. Huang"}, "abstract": "Visual and auditory modalities are two of the most commonly used media in interactions between humans. The authors describe a system to continuously monitor the user's voice and facial motions for recognizing emotional expressions. Such an ability is crucial for intelligent computers that take on a social role such as an actor or a companion. We outline methods to extract audio and visual features useful for classifying emotions. Audio and visual information must be handled appropriately in single-modal and bimodal situations. We report audio-only and video-only emotion recognition on the same subjects, in person-dependent and person-independent fashions, and outline methods to handle bimodal recognition"}, "references": ["https://www.researchgate.net/publication/21960201_Automatic_Segmentation_of_Speech_Into_Syllabic_Units", "https://www.researchgate.net/publication/220182026_Coding_analysis_interpretation_recognition_of_facial_expressions_IEEE_Trans_Pattern_Anal_Mach_Intell", "https://www.researchgate.net/publication/2492899_Adding_The_Affective_Dimension_A_New_Look_In_Speech_Analysis_And_Synthesis", "https://www.researchgate.net/publication/221619409_A_SNoW-based_face_detector", "https://www.researchgate.net/publication/232643876_Recognizing_multiple_persons'_facial_expressions_using_HMM_based_on_automatic_extraction_of_significant_frames_from_image_sequences", "https://www.researchgate.net/publication/246964015_Non-Rigid_Motion_Modeling_And_Analysis_In_Video_Sequence_For_Realistic_Facial_Animation", "https://www.researchgate.net/publication/3613036_Tracking_and_recognizing_rigid_and_non-rigid_facial_motions_usinglocal_parametric_models_of_image_motion", "https://www.researchgate.net/publication/3784455_Emotion_recognition_from_audiovisual_information"]}