{"cited_in": ["https://www.researchgate.net/publication/288890433_An_Overview_of_Emerging_Technologies_for_High_Efficiency_3D_Video_Coding", "https://www.researchgate.net/publication/287853663_Remote_Health_Coaching_System_and_Human_Motion_Data_Analysis_for_Physical_Therapy_with_Microsoft_Kinect"], "datas": {"publication_uid": "283327858", "title": "Unsupervised Temporal Segmentation of Repetitive Human Actions Based on Kinematic Modeling and Frequency Analysis", "authors": {"1": "Qifei Wang", "4": "Ruzena Bajcsy", "3": "Ferda Ofli", "2": "Gregorij Kurillo"}, "abstract": "  ABSTRACT In this paper, we propose a method for temporal segmentation of human repetitive actions based on frequency analysis of kinematic parameters, zero-velocity crossing detection, and adaptive k-means clustering. Since the human motion data may be captured with different modalities which have different temporal sampling rate and accuracy (e.g., optical motion capture systems vs. Microsoft Kinect), we first apply a generic full-body kinematic model with an unscented Kalman filter to convert the motion data into a unified representation that is robust to noise. Furthermore, we extract the most representative kinematic parameters via the primary frequency analysis. The sequences are segmented based on zero-velocity crossing of the selected parameters followed by an adaptive k-means clustering to identify the repetition segments. Experimental results demonstrate that for the motion data captured by both the motion capture system and the Microsoft Kinect, our proposed algorithm obtains robust segmentation of repetitive action sequences.  "}, "references": ["https://www.researchgate.net/publication/221474944_Segmenting_Motion_Capture_Data_into_Distinct_Behaviors", "https://www.researchgate.net/publication/2921103_Automated_Derivation_of_Primitives_for_Movement_Classification", "https://www.researchgate.net/publication/236675438_On-Line_Segmentation_of_Human_Motion_for_Automated_Rehabilitation_Exercise_Analysis", "https://www.researchgate.net/publication/237752375_Review_article_A_survey_of_advances_in_vision-based_human_motion_capture_and_analysis", "https://www.researchgate.net/publication/231521391_Documentation_Mocap_database_HDM05", "https://www.researchgate.net/publication/220789312_Real-Time_Classification_of_Dance_Gesturesfrom_Skeleton_Animation", "https://www.researchgate.net/publication/221364708_Real-Time_Human_Pose_Recognition_in_Parts_from_Single_Depth_Images", "https://www.researchgate.net/publication/51914487_Unstructured_Human_Activity_Detection_from_RGBD_Images", "https://www.researchgate.net/publication/262484493_Efficient_Unsupervised_Temporal_Segmentation_of_Motion_Data", "https://www.researchgate.net/publication/3873439_The_Unscented_Kalman_Filter_for_Nonlinear_Estimation", "https://www.researchgate.net/publication/261038502_Human_behavior_segmentation_and_recognition_using_Continuous_Linear_Dynamic_System", "https://www.researchgate.net/publication/254058710_Microsoft_Kinect_Sensor_and_Its_Effect"]}