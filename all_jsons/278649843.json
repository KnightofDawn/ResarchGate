{"cited_in": ["https://www.researchgate.net/publication/278322885_Effect_of_Initial_Conditioning_of_Reinforcement_Learning_Agents_on_Feedback_Control_Tasks_over_Continuous_State_and_Action_Spaces"], "datas": {"publication_uid": "278649843", "title": "An Empirical Study of Actor-Critic Methods for Feedback Controllers of Ball-Screw Drivers", "authors": {"1": "Borja Fernandez-Gauna", "4": "Manuel Gra\u00f1a", "3": "Ismael Etxeberria-Agiriano", "2": "Igor Ansoategui"}, "abstract": "In this paper we study the use of Reinforcement Learning Actor-Critic methods to learn the control of a ball-screw feed drive. We have tested three different actors: Q-value based, Policy Gradient and CACLA actors. We have paid special attention to the sensibility to suboptimal learning gain tuning. As a benchmark, we have used randomly-initialized PID controllers. CACLA provides an stable control comparable to the best heuristically tuned PID controller, despite its lack of knowledge of the actual error value."}, "references": ["https://www.researchgate.net/publication/220344042_Riedmiller_M_Reinforcement_learning_in_feedback_control_Challenges_and_benchmarks_from_technical_process_control_Machine_Learning_841-2_137-169"]}