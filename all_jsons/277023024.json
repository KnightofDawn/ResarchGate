{"cited_in": ["https://www.researchgate.net/publication/289992926_A_Generic_Software_Platform_for_Brain-inspired_Cognitive_Computing", "https://www.researchgate.net/publication/286301662_Simple_Baseline_for_Visual_Question_Answering", "https://www.researchgate.net/publication/275974823_Ask_Your_Neurons_A_Neural-based_Approach_to_Answering_Questions_about_Images", "https://www.researchgate.net/publication/284219144_Learning_Deep_Structure-Preserving_Image-Text_Embeddings", "https://www.researchgate.net/publication/284219941_Yin_and_Yang_Balancing_and_Answering_Binary_Visual_Questions", "https://www.researchgate.net/publication/283761954_Visual7W_Grounded_Question_Answering_in_Images", "https://www.researchgate.net/publication/283658780_Explicit_Knowledge-based_Reasoning_for_Visual_Question_Answering", "https://www.researchgate.net/publication/283658912_Generation_and_Comprehension_of_Unambiguous_Object_Descriptions"], "datas": {"publication_uid": "277023024", "title": "Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering", "authors": {"2": "Junhua Mao", "6": "Wei Xu", "1": "Haoyuan Gao", "4": "Zhiheng Huang", "3": "Jie Zhou", "5": "Lei Wang"}, "abstract": "  ABSTRACT In this paper, we present the mQA model, which is able to answer questions about the content of an image. The answer can be a sentence, a phrase or a single word. Our model contains four components: a Long-Short Term Memory (LSTM) to extract the question representation, a Convolutional Neural Network (CNN) to extract the visual representation, a LSTM for storing the linguistic context in an answer, and a fusing component to combine the information from the first three components and generate the answer. We construct a Freestyle Multilingual Image Question Answering (FM-IQA) dataset to train and evaluate our mQA model. It contains over 120,000 images and 250,000 freestyle Chinese question-answer pairs and their English translations. The quality of the generated answers of our mQA model on this dataset are evaluated by human judges through a Turing Test. Specifically, we mix the answers provided by humans and our model. The human judges need to distinguish our model from the human. They will also provide a score (i.e. 0, 1, 2, the larger the better) indicating the quality of the answer. We propose strategies to monitor the quality of this evaluation process. The experiments show that in 64.7% of cases, the human judges cannot distinguish our model from humans. The average score is 1.454 (1.918 for human).  "}, "references": ["https://www.researchgate.net/publication/275897099_VQA_Visual_Question_Answering", "https://www.researchgate.net/publication/220877439_VizWiz_Nearly_Real-time_Answers_to_Visual_Questions", "https://www.researchgate.net/publication/269932975_Semantic_Image_Segmentation_with_Deep_Convolutional_Nets_and_Fully_Connected_CRFs", "https://www.researchgate.net/publication/268524772_Learning_a_Recurrent_Visual_Representation_for_Image_Caption_Generation", "https://www.researchgate.net/publication/262877889_Learning_Phrase_Representations_using_RNN_Encoder-Decoder_for_Statistical_Machine_Translation", "https://www.researchgate.net/publication/268525836_Long-term_Recurrent_Convolutional_Networks_for_Visual_Recognition_and_Description", "https://www.researchgate.net/publication/222449846_Finding_Structure_in_Time", "https://www.researchgate.net/publication/268525230_From_Captions_to_Visual_Concepts_and_Back", "https://www.researchgate.net/publication/273387445_Visual_Turing_test_for_computer_vision_systems", "https://www.researchgate.net/publication/258374356_Rich_Feature_Hierarchies_for_Accurate_Object_Detection_and_Semantic_Segmentation", "https://www.researchgate.net/publication/248768967_The_IAPR_TC12_Benchmark_A_New_Evaluation_Resource_for_Visual_Information_Systems", "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory", "https://www.researchgate.net/publication/269339562_Deep_Visual-Semantic_Alignments_for_Generating_Image_Descriptions", "https://www.researchgate.net/publication/268155634_Unifying_Visual-Semantic_Embeddings_with_Multimodal_Neural_Language_Models", "https://www.researchgate.net/publication/268988559_Fisher_Vectors_Derived_from_Hybrid_Gaussian-Laplacian_Mixture_Models_for_Image_Annotation", "https://www.researchgate.net/publication/228346240_METEOR_An_automatic_metric_for_MT_evaluation_with_high_levels_of_correlation_with_human_judgments", "https://www.researchgate.net/publication/270222084_Simple_Image_Description_Generator_via_a_Linear_Phrase-Based_Approach", "https://www.researchgate.net/publication/263002356_Microsoft_COCO_Common_Objects_in_Context", "https://www.researchgate.net/publication/266376838_A_Multi-World_Approach_to_Question_Answering_about_Real-World_Scenes_based_on_Uncertain_Input", "https://www.researchgate.net/publication/275974823_Ask_Your_Neurons_A_Neural-based_Approach_to_Answering_Questions_about_Images", "https://www.researchgate.net/publication/269935372_Deep_Captioning_with_Multimodal_Recurrent_Neural_Networks_m-RNN", "https://www.researchgate.net/publication/275588292_Learning_like_a_Child_Fast_Novel_Visual_Concept_Learning_from_Sentence_Descriptions_of_Images", "https://www.researchgate.net/publication/266560687_Explain_Images_with_Multimodal_Recurrent_Neural_Networks", "https://www.researchgate.net/publication/269997665_Learning_Longer_Memory_in_Recurrent_Neural_Networks", "https://www.researchgate.net/publication/221489926_Recurrent_neural_network_based_language_model", "https://www.researchgate.net/publication/221345737_Rectified_Linear_Units_Improve_Restricted_Boltzmann_Machines_Vinod_Nair", "https://www.researchgate.net/publication/2588204_BLEU_a_Method_for_Automatic_Evaluation_of_Machine_Translation", "https://www.researchgate.net/publication/276149583_Image_Question_Answering_A_Visual_Semantic_Embedding_Model_and_a_New_Dataset", "https://www.researchgate.net/publication/265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition", "https://www.researchgate.net/publication/265554383_Sequence_to_Sequence_Learning_with_Neural_Networks", "https://www.researchgate.net/publication/265787949_Going_Deeper_with_Convolutions", "https://www.researchgate.net/publication/256297773_Joint_Video_and_Text_Parsing_for_Understanding_Events_and_Answering_Queries", "https://www.researchgate.net/publication/224982542_Computing_Machinery_and_Intelligence", "https://www.researchgate.net/publication/268689555_CIDEr_Consensus-based_Image_Description_Evaluation", "https://www.researchgate.net/publication/268451983_Show_and_Tell_A_Neural_Image_Caption_Generator", "https://www.researchgate.net/publication/230585379_Verbs_Semantics_and_Lexical_Selection", "https://www.researchgate.net/publication/272194766_Show_Attend_and_Tell_Neural_Image_Caption_Generation_with_Visual_Attention"]}