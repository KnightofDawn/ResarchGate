{"cited_in": ["https://www.researchgate.net/publication/265225609_Considering_saliency_in_a_perception_inspired_gamut_reduction_algorithm", "https://www.researchgate.net/publication/266149577_Toward_Statistical_Modeling_of_Saccadic_Eye-Movement_and_Visual_Saliency", "https://www.researchgate.net/publication/285202090_Influence_factors_of_contrast_sensitivity_function_in_stereoscopic_displays", "https://www.researchgate.net/publication/276172108_Chemical_Reaction_Optimization_for_Feature_Combination_in_Bio-inspired_Visual_Attention"], "datas": {"publication_uid": "256837363", "title": "Low-Level Spatiochromatic Grouping for Saliency Estimation", "authors": {"1": "Naila Murray", "4": "C. Alejandro P\u00e1rraga", "3": "Xavier Otazu", "2": "Maria Vanrell"}, "abstract": "We propose a saliency model termed SIM (saliency by induction mechanisms), which is based on a low-level spatiochromatic model that has successfully predicted chromatic induction phenomena. In so doing, we hypothesize that the low-level visual mechanisms that enhance or suppress image detail are also responsible for making some image regions more salient. Moreover, SIM adds geometrical grouplets to enhance complex low-level features such as corners, and suppress relatively simpler features such as edges. Since our model has been fitted on psychophysical chromatic induction data, it is largely nonparametric. SIM outperforms state-of-the-art methods in predicting eye fixations on two datasets and using two metrics."}, "references": ["https://www.researchgate.net/publication/223969599_State-of-the-Art_in_Visual_Attention_Modeling", "https://www.researchgate.net/publication/3192913_A_Model_of_Saliency-based_Visual_Attention_for_Rapid_Scene_Analysis", "https://www.researchgate.net/publication/51520719_Image_Signature_Highlighting_Sparse_Salient_Regions", "https://www.researchgate.net/publication/49847940_Color_in_the_Cortex_Single-_and_double-opponent_cells", "https://www.researchgate.net/publication/12409568_Suppression_outside_the_classical_cortical_receptive_field", "https://www.researchgate.net/publication/221109992_Learning_to_Predict_Where_Humans_Look", "https://www.researchgate.net/publication/221619044_Saliency_Based_on_Information_Maximization", "https://www.researchgate.net/publication/40869094_Static_and_space-time_visual_saliency_detection_by_self-resemblance_J_Vis_915_1-27", "https://www.researchgate.net/publication/13815618_Similar_mechanisms_underlie_simultaneous_brightness_contrast_and_grating_induction", "https://www.researchgate.net/publication/40443832_A_High-Throughput_Screening_Approach_to_Discovering_Good_Forms_of_Biologically_Inspired_Visual_Representation", "https://www.researchgate.net/publication/47675540_Toward_a_unified_chromatic_induction_model", "https://www.researchgate.net/publication/221618957_Dynamic_Visual_Attention_Searching_for_coding_length_increments", "https://www.researchgate.net/publication/227178280_Learning_visual_saliency_by_combining_feature_maps_in_a_nonlinear_manner_using_AdaBoost", "https://www.researchgate.net/publication/221363131_Saliency_estimation_using_a_non-parametric_low-level_vision_model", "https://www.researchgate.net/publication/12076686_Computational_Modeling_of_Visual_Attention", "https://www.researchgate.net/publication/7807727_Components_of_bottom-up_gaze_allocation_in_natural_images_Vision_Res_45_2397-2416", "https://www.researchgate.net/publication/21154369_Zeki_S_et_al_A_direct_demonstration_of_functional_specialization_in_human_visual_cortex_J_Neurosci_11_641-649", "https://www.researchgate.net/publication/222533078_Geometrical_grouplets", "https://www.researchgate.net/publication/221619843_Graph-Based_Visual_Saliency", "https://www.researchgate.net/publication/23790320_SUN_A_Bayesian_framework_for_saliency_using_nature_statistics", "https://www.researchgate.net/publication/10375326_Attneave_F_Informational_aspects_of_visual_perception_Psychol_Rev_61_183-193", "https://www.researchgate.net/publication/23790302_On_the_plausibility_of_the_discriminant_center-surround_hypothesis_for_visual_saliency", "https://www.researchgate.net/publication/221618431_A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency", "https://www.researchgate.net/publication/11644623_Estimating_receptive_field_size_from_fMRI_data_in_human_striate_and_extrastriate_visual_cortex", "https://www.researchgate.net/publication/8216184_Cavanaugh_JR_Bair_W_Movshon_JA_Nature_and_interaction_of_signals_from_the_receptive_field_center_and_surround_in_macaque_V1_neurons_J_Neurophysiol_88_2530-2546", "https://www.researchgate.net/publication/243787382_Investigation_of_a_sensorimotor_system_for_saccadic_scene_analysis_An_integrated_approach", "https://www.researchgate.net/publication/2637582_Modeling_Surround_Suppression_in_V1_Neurons_with_a_Statistically-Derived_Normalization_Model", "https://www.researchgate.net/publication/19162987_Mullen_K_T_The_contrast_sensitivity_of_human_colour_vision_to_red-green_and_blue-yellow_chromatic_gratings_J_PhysiolLond_359_381-400", "https://www.researchgate.net/publication/221949535_Li_C-Y_Li_W_Extensive_integration_field_beyond_the_classical_receptive_field_of_cat_striate_cortical_neurons_-_classification_and_tuning_properties_Vision_Res_34_2337-2355"]}