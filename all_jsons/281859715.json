{"cited_in": [], "datas": {"publication_uid": "281859715", "title": "Pororobot: A Deep Learning Robot That Plays Video Q&A Games", "authors": {"2": "Chang-Jun Nan", "6": "Byoung-Tak Zhang", "1": "Kyung-Min Kim", "4": "NAVER", "3": "Jung-Woo Ha", "5": "Yu-Jung Heo"}, "abstract": "Recent progress in machine learning has lead to great advancements in robot intelligence and human-robot interaction (HRI). It is reported that robots can deeply understand visual scene information and describe the scenes in natural language using object recognition and natural language processing methods. Image-based question and answering (Q&A) systems can be used for enhancing HRI. However, despite these successful results, several key issues still remain to be discussed and improved. In particular, it is essential for an agent to act in a dynamic, uncertain, and asynchronous environment for achieving human-level robot intelligence. In this paper, we propose a prototype system for a video Q&A robot \" Pororobot \". The system uses the state-of-the-art machine learning methods such as a deep concept hierarchy model. In our scenario, a robot and a child plays a video Q&A game together under real world environments. Here we demonstrate preliminary results of the proposed system and discuss some directions as future works."}, "references": ["https://www.researchgate.net/publication/268525230_From_Captions_to_Visual_Concepts_and_Back", "https://www.researchgate.net/publication/271041318_A_Socially_Assistive_Robot_Exercise_Coach_for_the_Elderly", "https://www.researchgate.net/publication/259127160_Storytelling_by_a_kindergarten_social_assistive_robot_A_tool_for_constructive_learning_in_preschool_education", "https://www.researchgate.net/publication/258374356_Rich_Feature_Hierarchies_for_Accurate_Object_Detection_and_Semantic_Segmentation", "https://www.researchgate.net/publication/268051812_Automated_Construction_of_Visual-Linguistic_Knowledge_via_Concept_Learning_from_Cartoon_Videos", "https://www.researchgate.net/publication/269339562_Deep_Visual-Semantic_Alignments_for_Generating_Image_Descriptions", "https://www.researchgate.net/publication/266654799_Robotic_learning_companions_for_early_language_development", "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks", "https://www.researchgate.net/publication/262405053_Personalizing_robot_tutors_to_individuals'_learning_differences", "https://www.researchgate.net/publication/275974823_Ask_Your_Neurons_A_Neural-based_Approach_to_Answering_Questions_about_Images", "https://www.researchgate.net/publication/257882504_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality", "https://www.researchgate.net/publication/2588204_BLEU_a_Method_for_Automatic_Evaluation_of_Machine_Translation", "https://www.researchgate.net/publication/276149583_Image_Question_Answering_A_Visual_Semantic_Embedding_Model_and_a_New_Dataset", "https://www.researchgate.net/publication/268451983_Show_and_Tell_A_Neural_Image_Caption_Generator", "https://www.researchgate.net/publication/267242847_Sparse_Population_Code_Models_of_Word_Learning_in_Concept_Drift"]}