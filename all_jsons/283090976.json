{"cited_in": [], "datas": {"publication_uid": "283090976", "title": "A Real-Time Human Action Recognition System Using Depth and Inertial Sensor Fusion", "authors": {"1": "Chen Chen"}, "abstract": "  ABSTRACT This paper presents a human action recognition system that runs in real-time and uses a depth camera and an inertial sensor simultaneously based on a previously developed sensor fusion method. Computationally efficient depth image features and inertial signals features are fed into two computationally efficient collaborative representative classifiers. A decision-level fusion is then performed. The developed real-time system is evaluated using a publicly available multimodal human action recognition dataset by considering a comprehensive set of human actions. The overall classification rate of the developed real-time system is shown to be more than 97% which is at least 9% higher than when each sensing modality is used individually. The results from both offline and real-time experimentations demonstrate the effectiveness of the system and its real-time throughputs. Index Terms\u2014Human action recognition, real-time human action recognition system, depth camera sensor, wearable inertial sensor, sensor fusion  "}, "references": ["https://www.researchgate.net/publication/4090526_Recognizing_human_actions_A_local_SVM_approach", "https://www.researchgate.net/publication/221362776_Hierarchical_spatio-temporal_context_modeling_for_action_recognition", "https://www.researchgate.net/publication/221361842_Learning_realistic_human_actions_from_movies_In_IEEE_CVPR", "https://www.researchgate.net/publication/224165257_Action_recognition_based_on_a_bag_of_3D_points", "https://www.researchgate.net/publication/282716855_Action_recognition_from_depth_sequences_using_depth_motion_maps-based_local_binary_patterns", "https://www.researchgate.net/publication/256440981_Real-time_human_action_recognition_based_on_depth_motion_maps", "https://www.researchgate.net/publication/261292683_Feature_Selection_and_Activity_Recognition_System_Using_a_Single_Triaxial_Accelerometer", "https://www.researchgate.net/publication/220497531_Distributed_recognition_of_human_actions_using_wearable_motion_sensor_networks", "https://www.researchgate.net/publication/265335891_A_Medication_Adherence_Monitoring_System_for_Pill_Bottles_Based_on_a_Wearable_Inertial_Sensor", "https://www.researchgate.net/publication/262172347_Indoor_Activity_Recognition_by_Combining_One-vs-All_Neural_Network_Classifiers_Exploiting_Wearable_and_Depth_Sensors", "https://www.researchgate.net/publication/260246979_Fusion_of_Inertial_and_Depth_Sensor_Data_for_Robust_Hand_Gesture_Recognition", "https://www.researchgate.net/publication/267027457_Improving_Human_Action_Recognition_Using_Fusion_of_Depth_Camera_and_Inertial_Sensors", "https://www.researchgate.net/publication/265294495_Home-based_Senior_Fitness_Test_Measurement_System_Using_Collaborative_Inertial_and_Depth_Sensors", "https://www.researchgate.net/publication/233786470_Berkeley_MHAD_A_comprehensive_Multimodal_Human_Action_Database", "https://www.researchgate.net/publication/221111435_Sparse_representation_or_collaborative_representation_which_helps_face_recognition_IEEE_Int_Conf_Comput_Vis", "https://www.researchgate.net/publication/229913006_A_Mathematical_Theory_of_Evidence", "https://www.researchgate.net/publication/261504390_G3D_A_gaming_action_dataset_and_real_time_action_recognition_evaluation_framework", "https://www.researchgate.net/publication/280032653_Inertial_Sensor-Based_Touch_and_Shake_Metaphor_for_Expressive_Control_of_3D_Virtual_Avatars"]}