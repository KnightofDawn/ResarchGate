{"cited_in": [], "datas": {"publication_uid": "283748673", "title": "Co-occurrence Feature Learning for Skeleton based Action Recognition using Regularized Deep LSTM Networks", "authors": {"2": "Cuiling Lan", "6": "Wenjun Zeng", "1": "Wentao Zhu", "4": "Yanghao Li", "3": "Junliang Xing", "5": "Li Shen"}, "abstract": "Skeleton based action recognition distinguishes human actions using the trajectories of skeleton joints, which provide a very good representation for describing actions. Considering that recurrent neural networks (RNNs) with Long Short-Term Memory (LSTM) can learn feature representations and model long-term temporal dependencies automatically, we propose an end-to-end fully connected deep LSTM network for skeleton based action recognition. Inspired by the observation that the co-occurrences of the joints intrinsically characterize human actions, we take the skeleton as the input at each time slot and introduce a novel regularization scheme to learn the co-occurrence features of skeleton joints. To train the deep LSTM network effectively, we propose a new dropout algorithm which simultaneously operates on the gates, cells, and output responses of the LSTM neurons. Experimental results on three human action recognition datasets consistently demonstrate the effectiveness of the proposed model. The attachment is the labelled CMU dataset."}, "references": ["https://www.researchgate.net/publication/258818168_Speech_Recognition_with_Deep_Recurrent_Neural_Networks", "https://www.researchgate.net/publication/36419563_Supervised_Sequence_Labelling_with_Recurrent_Neural_Networks", "https://www.researchgate.net/publication/220184451_Efficient_Content-Based_Retrieval_of_Motion_Capture_Data", "https://www.researchgate.net/publication/259334958_Dropout_Improves_Recurrent_Neural_Networks_for_Handwriting_Recognition", "https://www.researchgate.net/publication/4193939_Conditional_models_for_contextual_human_motion_recognition", "https://www.researchgate.net/publication/286794765_Dropout_A_simple_way_to_prevent_neural_networks_from_overfitting", "https://www.researchgate.net/publication/51914487_Unstructured_Human_Activity_Detection_from_RGBD_Images", "https://www.researchgate.net/publication/261283562_Mining_Actionlet_Ensemble_for_Action_Recognition_with_Depth_Cameras", "https://www.researchgate.net/publication/256979980_A_Survey_of_Vision-Based_Methods_for_Action_Representation_Segmentation_and_Recognition", "https://www.researchgate.net/publication/233786470_Berkeley_MHAD_A_comprehensive_Multimodal_Human_Action_Database", "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks", "https://www.researchgate.net/publication/7647316_Schmidhuber_J_Framewise_phoneme_classification_with_bidirectional_LSTM_and_other_neural_network_architectures_Neural_Netw_185--6_602-610", "https://www.researchgate.net/publication/259519992_Effective_3D_action_recognition_using_EigenJoints", "https://www.researchgate.net/publication/238951495_Classifying_and_Visualizing_Motion_Capture_Sequences_using_Deep_Neural_Networks", "https://www.researchgate.net/publication/261421354_Two-person_interaction_detection_using_body-pose_features_and_multiple_instance_learning", "https://www.researchgate.net/publication/265469170_Recurrent_Neural_Network_Regularization", "https://www.researchgate.net/publication/265787949_Going_Deeper_with_Convolutions", "https://www.researchgate.net/publication/261421353_View_invariant_human_action_recognition_using_histograms_of_3D_joints", "https://www.researchgate.net/publication/257023032_BLSTM-RNN_Based_3D_Gesture_Classification", "https://www.researchgate.net/publication/285471343_Interactive_body_part_contrast_mining_for_human_interaction_recognition", "https://www.researchgate.net/publication/279867761_Visual_Perception_of_biological_motion_and_a_model_for_its_analysis", "https://www.researchgate.net/publication/231521391_Documentation_Mocap_database_HDM05", "https://www.researchgate.net/publication/270819321_Golay_MJE_Smoothing_and_Differentiation_of_Data_by_Simplified_Least_Squares_Procedures_Anal_Chem_36_1627-1639"]}