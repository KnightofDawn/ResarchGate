{"cited_in": ["https://www.researchgate.net/publication/282403687_Semantics_Representations_and_Grammars_for_Deep_Learning", "https://www.researchgate.net/publication/283433446_Learning_Continuous_Control_Policies_by_Stochastic_Value_Gradients", "https://www.researchgate.net/publication/291186593_Grammars_for_Games_A_Gradient-Based_Game-Theoretic_Framework_for_Optimization_in_Deep_Learning"], "datas": {"publication_uid": "281632506", "title": "Compatible Value Gradients for Reinforcement Learning of Continuous Deep Policies", "authors": {"1": "David Balduzzi", "2": "Muhammad Ghifary"}, "abstract": "  ABSTRACT This paper proposes GProp, a deep reinforcement learning algorithm for continuous policies with compatible function approximation. The algorithm is based on two innovations. Firstly, we present a temporal-difference based method for learning the gradient of the value-function. Secondly, we present the deviator-actor-critic (DAC) model, which comprises three neural networks that estimate the value function, its gradient, and determine the actor's policy respectively. We evaluate GProp on two challenging tasks: a contextual bandit problem constructed from nonparametric regression datasets that is designed to probe the ability of reinforcement learning algorithms to accurately estimate gradients; and the octopus arm, a challenging reinforcement learning benchmark. GProp is competitive with fully supervised methods on the bandit task and achieves the best performance to date on the octopus arm.  "}, "references": ["https://www.researchgate.net/publication/2948444_Unifying_Temporal_and_Structural_Credit_Assignment_Problems", "https://www.researchgate.net/publication/225152490_Analyzing_and_visualizing_multiagent_rewards_in_dynamic_and_stochastic_domains", "https://www.researchgate.net/publication/221345670_Residual_Algorithms_Reinforcement_Learning_with_Function_Approximation", "https://www.researchgate.net/publication/281607708_Deep_Online_Convex_Optimization_by_Putting_Forecaster_to_Sleep", "https://www.researchgate.net/publication/268748241_Kickback_cuts_Backprop's_red-tape_Biologically_plausible_credit_assignment_in_neural_networks", "https://www.researchgate.net/publication/232457016_Neuron_like_elements_that_can_solve_difficult_learning_control_problems", "https://www.researchgate.net/publication/233753224_Theano_new_features_and_speed_improvements", "https://www.researchgate.net/publication/261153441_Improving_deep_neural_networks_for_LVCSR_using_rectified_linear_units_and_dropout", "https://www.researchgate.net/publication/256461527_A_Survey_on_Policy_Search_for_Robotics", "https://www.researchgate.net/publication/274459304_Doubly_Robust_Policy_Evaluation_and_Optimization", "https://www.researchgate.net/publication/221618270_Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods", "https://www.researchgate.net/publication/236153622_Value-Gradient_Learning", "https://www.researchgate.net/publication/258998814_An_Equivalence_Between_Adaptive_Dynamic_Programming_With_a_Critic_and_Backpropagation_Through_Time", "https://www.researchgate.net/publication/1957347_Online_convex_optimization_in_the_bandit_setting_Gradient_descent_without_a_gradient", "https://www.researchgate.net/publication/2889388_Coordinated_Reinforcement_Learning", "https://www.researchgate.net/publication/220344042_Riedmiller_M_Reinforcement_learning_in_feedback_control_Challenges_and_benchmarks_from_technical_process_control_Machine_Learning_841-2_137-169", "https://www.researchgate.net/publication/221618428_Learning_to_Control_an_Unstable_System_with_Forward_Modeling", "https://www.researchgate.net/publication/221619376_A_Natural_Policy_Gradient", "https://www.researchgate.net/publication/2613507_OnActor-Critic_Algorithms", "https://www.researchgate.net/publication/274572264_End-to-End_Training_of_Deep_Visuomotor_Policies", "https://www.researchgate.net/publication/221345737_Rectified_Linear_Units_Improve_Restricted_Boltzmann_Machines_Vinod_Nair", "https://www.researchgate.net/publication/239583247_Problem_Complexity_and_Method_Efficiency_in_Optimization", "https://www.researchgate.net/publication/221617864_Local_Gaussian_Process_Regression_for_Real_Time_Online_Model_Learning", "https://www.researchgate.net/publication/224685146_Policy_Gradient_Methods_for_Robotics", "https://www.researchgate.net/publication/243634308_Advanced_Adaptive_Critic_Designs", "https://www.researchgate.net/publication/224237088_Information-Based_Complexity_Feedback_and_Dynamics_in_Convex_Programming", "https://www.researchgate.net/publication/272161307_Reinforcement_Learning_An_Introduction", "https://www.researchgate.net/publication/221344791_Fast_gradient-descent_methods_for_temporal-difference_learning_with_linear_function_approximation", "https://www.researchgate.net/publication/221618863_A_Convergent_On_Temporal-difference_Algorithm_for_Off-policy_Learning_with_Linear_Function_Approximation", "https://www.researchgate.net/publication/272195531_From_Pixels_to_Torques_Policy_Learning_with_Deep_Dynamical_Models", "https://www.researchgate.net/publication/221533916_On-Line_Learning_Control_by_Association_and_Reinforcement", "https://www.researchgate.net/publication/2426555_Simple_Statistical_Gradient-Following_Algorithms_for_Connectionist_Reinforcement_Learning", "https://www.researchgate.net/publication/261159435_On_rectified_linear_units_for_speech_processing"]}