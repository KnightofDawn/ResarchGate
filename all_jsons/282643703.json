{"cited_in": [], "datas": {"publication_uid": "282643703", "title": "Multimodal Human Activity Recognition for Industrial Manufacturing Processes in Robotic Workcells", "authors": {"1": "Alina Roitberg", "4": "Markus Rickert", "3": "Alexander Perzylo", "2": "Nikhil Somani", "5": "Alois Knoll"}, "abstract": "We present an approach for monitoring and interpreting human activities based on a novel multimodal vision-based interface, aiming at improving the efficiency of human-robot interaction (HRI) in industrial environments. Multi-modality is an important concept in this design, where we combine inputs from several state-of-the-art sensors to provide a variety of information, e.g. skeleton and fingertip poses. Based on typical industrial workflows, we derived multiple levels of human activity labels, including large-scale activities (e.g. assembly) and simpler sub-activities (e.g. hand gestures), creating a duration- and complexity-based hierarchy. We train supervised generative classifiers for each activity level and combine the output of this stage with a trained Hierarchical Hidden Markov Model (HHMM), which models not only the temporal aspects between the activities on the same level, but also the hierarchical relationships between the levels."}, "references": ["https://www.researchgate.net/publication/220566360_Human_Activity_Analysis_A_Review", "https://www.researchgate.net/publication/224323283_In_defense_of_nearest-neighbor_based_image_classification_In_IEEE_CVPR", "https://www.researchgate.net/publication/2266784_The_Hierarchical_Hidden_Markov_Model_Analysis_and_Applications", "https://www.researchgate.net/publication/274662444_Human_Action_Recognition_Using_APJ3D_and_Random_Forests", "https://www.researchgate.net/publication/261091587_Gestures_for_industry_Intuitive_human-robot_communication_from_human_observation", "https://www.researchgate.net/publication/221281001_Human_Activity_Recognition_Using_Sequences_of_Postures", "https://www.researchgate.net/publication/231609161_Learning_Human_Activities_and_Object_Affordances_from_RGB-D_Videos", "https://www.researchgate.net/publication/221063421_Human_workflow_analysis_using_3D_occupancy_grid_hand_tracking_in_a_human-robot_collaboration_scenario", "https://www.researchgate.net/publication/4156338_Learning_and_Detecting_Activities_From_Movement_Trajectories_Using_the_Hierarchical_Hidden_Markov_Model", "https://www.researchgate.net/publication/230627729_Sequence_of_the_Most_Informative_Joints_SMIJ_A_new_representation_for_human_skeletal_action_recognition", "https://www.researchgate.net/publication/3249683_An_introduction_to_hidden_Markov_models_IEEE_ASSP_Mag", "https://www.researchgate.net/publication/282295683_Human_Activity_Recognition_in_the_Context_of_Industrial_Human-Robot_Interaction", "https://www.researchgate.net/publication/51914487_Unstructured_Human_Activity_Detection_from_RGBD_Images", "https://www.researchgate.net/publication/3513086_Recognizing_human_action_in_time-sequential_images_using_hidden_Markov_model", "https://www.researchgate.net/publication/261468406_Fusing_Spatiotemporal_Features_and_Joints_for_3D_Action_Recognition"]}