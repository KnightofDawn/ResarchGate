{"cited_in": ["https://www.researchgate.net/publication/291331681_Deep_Learning_the_Dynamic_Appearance_and_Shape_of_Facial_Action_Units", "https://www.researchgate.net/publication/278743074_Emotion_recognition_from_mid_level_features", "https://www.researchgate.net/publication/278763516_Facial_Action_Units_Intensity_Estimation_by_the_Fusion_of_Features_with_Multi-kernel_Support_Vector_Machine", "https://www.researchgate.net/publication/276204408_Discriminant_Multi-Label_Manifold_Embedding_for_Facial_Action_Unit_Detection", "https://www.researchgate.net/publication/282912550_Magic_mirror_in_my_hand_what_is_the_sentiment_in_the_lens_An_action_unit_based_approach_for_mining_sentiments_from_multimedia_contents", "https://www.researchgate.net/publication/280852507_Depression_Estimation_Using_Audiovisual_Features_and_Fisher_Vector_Encoding", "https://www.researchgate.net/publication/262905659_Adaptive_feature_selection_and_data_pruning_for_3D_facial_expression_recognition_using_the_Kinect", "https://www.researchgate.net/publication/263237219_ERISA_BUILDING_EMOTIONALLY_REALISTIC_SOCIAL_GAME_AGENTS-COMPANIONS", "https://www.researchgate.net/publication/265592622_Magic_Mirror_in_my_Hand_what_is_the_Sentiment_in_the_Lens_an_Action_Unit_based_Approach_for_Mining_Sentiments_from_Multimedia_Contents", "https://www.researchgate.net/publication/269108094_Ensemble_CCA_for_Continuous_Emotion_Prediction", "https://www.researchgate.net/publication/287702683_AVEC_2014_-_3D_dimensional_affect_and_depression_recognition_challenge", "https://www.researchgate.net/publication/283018552_Facial_action_unit_intensity_estimation_using_rotation_invariant_features_and_regression_analysis", "https://www.researchgate.net/publication/282187512_Near-infrared_face_recognition_by_fusion_of_E-GV-LBP_and_FKNN", "https://www.researchgate.net/publication/276907567_Effects_of_cultural_characteristics_on_building_an_emotion_classifier_through_facial_expression_analysis", "https://www.researchgate.net/publication/275647713_Combining_modality-specific_extreme_learning_machines_for_emotion_recognition_in_the_wild", "https://www.researchgate.net/publication/276113061_Facial_expression_recognition_using_lp-norm_MKL_multiclass-SVM", "https://www.researchgate.net/publication/282301281_Automated_recognition_of_paralinguistic_signals_in_spoken_dialogue_systems_Ways_of_improvement", "https://www.researchgate.net/publication/289248756_Designing_a_Framework_for_Assisting_Depression_Severity_Assessment_from_Facial_Image_Analysis", "https://www.researchgate.net/publication/282573799_Contrasting_and_Combining_Least_Squares_Based_Learners_for_Emotion_Recognition_in_the_Wild"], "datas": {"publication_uid": "261206959", "title": "Local Gabor Binary Patterns from Three Orthogonal Planes for Automatic Facial Expression Recognition", "authors": {"1": "Timur R. Almaev", "2": "Michel Valstar"}, "abstract": "Facial actions cause local appearance changes over time, and thus dynamic texture descriptors should inherently be more suitable for facial action detection than their static variants. In this paper we propose the novel dynamic appearance descriptor Local Gabor Binary Patterns from Three Orthogonal Planes (LGBP-TOP), combining the previous success of LGBP-based expression recognition with TOP extensions of other descriptors. LGBP-TOP combines spatial and dynamic texture analysis with Gabor filtering to achieve unprecedented levels of recognition accuracy in real-time. While TOP features risk being sensitive to misalignment of consecutive face images, a rigorous analysis of the descriptor shows the relative robustness of LGBP-TOP to face registration errors caused by errors in rotational alignment. Experiments on the MMI Facial Expression and Cohn-Kanade databases show that for the problem of FACS Action Unit detection, LGBP-TOP outperforms both its static variant LGBP and the related dynamic appearance descriptor LBP-TOP."}, "references": ["https://www.researchgate.net/publication/226809922_FACSGen_A_Tool_to_Synthesize_Emotional_Facial_Expressions_Through_Systematic_Manipulation_of_Facial_Action_Units", "https://www.researchgate.net/publication/229059922_The_Repertoire_of_Nonverbal_Behavior_Categories_Origin_Usage_and_Coding", "https://www.researchgate.net/publication/224965929_Multilayer_Architectures_for_Facial_Action_Unit_Recognition", "https://www.researchgate.net/publication/6397809_Dynamic_Texture_Recognition_Using_Local_Binary_Patterns_with_an_Application_to_Facial_Expressions", "https://www.researchgate.net/publication/221304831_Face_Recognition_with_Local_Binary_Patterns", "https://www.researchgate.net/publication/220932220_V-LGBP_Volume_Based_Local_Gabor_Binary_Patterns_for_Face_Representation_and_Recognition", "https://www.researchgate.net/publication/221052262_How_to_distinguish_posed_from_spontaneous_smiles_using_geometric_features", "https://www.researchgate.net/publication/42803851_Automatic_Recognition_of_Facial_Actions_in_Spontaneous_Expressions", "https://www.researchgate.net/publication/222573706_Luettin_J_Automatic_Facial_Expression_Analysis_A_Survey_Pattern_Recognition_361_259-275", "https://www.researchgate.net/publication/254900623_Social_Signal_Processing_The_Research_Agenda", "https://www.researchgate.net/publication/224238114_Combining_LGBP_Histograms_with_AAM_coefficients_in_the_Multi-Kernel_SVM_framework_to_detect_Facial_Action_Units", "https://www.researchgate.net/publication/23493444_A_Survey_of_Affect_Recognition_Methods_Audio_Visual_and_Spontaneous_Expressions", "https://www.researchgate.net/publication/236072171_Local_Evidence_Aggregation_for_Regression-Based_Facial_Point_Detection", "https://www.researchgate.net/publication/222574859_Facial_expression_recognition_based_on_Local_Binary_Patterns_A_comprehensive_study", "https://www.researchgate.net/publication/221292325_Action_unit_detection_using_sparse_appearance_descriptors_in_space-time_video_volumes", "https://www.researchgate.net/publication/221052154_Spontaneous_vs_posed_facial_behavior_Automatic_analysis_of_brow_actions", "https://www.researchgate.net/publication/222399376_Boosting_encoded_dynamic_features_for_facial_expression_recognition_Pattern_Recogn_Lett_30_132-139", "https://www.researchgate.net/publication/227212967_Combining_SVMs_with_Various_Feature_Selection_Strategies", "https://www.researchgate.net/publication/8882449_Darwin_Deception_and_Facial_Expression", "https://www.researchgate.net/publication/3193420_Multiresolution_Gray-Scale_and_Rotation_Invariant_Texture_Classification_with_Local_Binary_Patterns", "https://www.researchgate.net/publication/225042550_Facial_Action_Recognition_Combining_Heterogeneous_Features_via_Multi-Kernel_Learning", "https://www.researchgate.net/publication/221292546_Facial_action_unit_recognition_with_sparse_representation", "https://www.researchgate.net/publication/3845529_Comprehesive_database_for_facial_expression_analysis", "https://www.researchgate.net/publication/257093264_Regression-based_intensity_estimation_of_facial_action_units", "https://www.researchgate.net/publication/220135732_Dynamic_soft_encoded_patterns_for_facial_event_analysis", "https://www.researchgate.net/publication/220508716_Local_Binary_Patterns_and_Its_Application_to_Facial_Image_Analysis_A_Survey"]}