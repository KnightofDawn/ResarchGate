{"cited_in": [], "datas": {"publication_uid": "288713513", "title": "Feedforward Sequential Memory Networks: A New Structure to Learn Long-term Dependency", "authors": {"2": "Cong Liu", "6": "Yu Hu", "1": "Shiliang Zhang", "4": "Si Wei", "3": "Hui Jiang", "5": "Lirong Dai"}, "abstract": "In this paper, we propose a novel neural network structure, namely \\emph{feedforward sequential memory networks (FSMN)}, to model long-term dependency in time series without using recurrent feedback. The proposed FSMN is a standard fully-connected feedforward neural network equipped with some learnable memory blocks in its hidden layers. The memory blocks use a tapped-delay line structure to encode the long context information into a fixed-size representation as short-term memory mechanism. We have evaluated the proposed FSMNs in several standard benchmark tasks, including speech recognition and language modelling. Experimental results have shown FSMNs significantly outperform the conventional recurrent neural networks (RNN), including LSTMs, in modeling sequential signals like speech or language. Moreover, FSMNs can be learned much more reliably and faster than RNNs or LSTMs due to the inherent non-recurrent model structure."}, "references": ["https://www.researchgate.net/publication/261119155_Applying_Convolutional_Neural_Networks_concepts_to_hybrid_NN-HMM_model_for_speech_recognition", "https://www.researchgate.net/publication/5583935_Learning_Long-Term_Dependencies_with_Gradient_Descent_Is_Difficult", "https://www.researchgate.net/publication/221618573_A_Neural_Probabilistic_Language_Model", "https://www.researchgate.net/publication/262877889_Learning_Phrase_Representations_using_RNN_Encoder-Decoder_for_Statistical_Machine_Translation", "https://www.researchgate.net/publication/269416998_Empirical_Evaluation_of_Gated_Recurrent_Neural_Networks_on_Sequence_Modeling", "https://www.researchgate.net/publication/220812758_Flexible_High_Performance_Convolutional_Neural_Networks_for_Image_Classification", "https://www.researchgate.net/publication/220655572_Context-Dependent_Pre-Trained_Deep_Neural_Networks_for_Large-Vocabulary_Speech_Recognition", "https://www.researchgate.net/publication/222449846_Finding_Structure_in_Time", "https://www.researchgate.net/publication/12292425_Learning_to_Forget_Continual_Prediction_with_LSTM", "https://www.researchgate.net/publication/255173850_Generating_Sequences_With_Recurrent_Neural_Networks", "https://www.researchgate.net/publication/258818168_Speech_Recognition_with_Deep_Recurrent_Neural_Networks", "https://www.researchgate.net/publication/267157056_Neural_Turing_Machines", "https://www.researchgate.net/publication/13853244_Long_Short-term_Memory", "https://www.researchgate.net/publication/285058764_Receptive_fields_binocular_interaction_and_functional_architecture_in_the_cat's_visual_cortex", "https://www.researchgate.net/publication/216792705_What_is_the_Best_Multi-Stage_Architecture_for_Object_Recognition", "https://www.researchgate.net/publication/281312208_Character-Aware_Neural_Language_Models", "https://www.researchgate.net/publication/267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks", "https://www.researchgate.net/publication/3302251_Face_Recognition_A_Convolutional_Neural_Network_Approach", "https://www.researchgate.net/publication/2985446_Gradient-based_learning_applied_to_document_recognition_Proc_IEEE", "https://www.researchgate.net/publication/224246503_Extensions_of_recurrent_neural_network_language_model", "https://www.researchgate.net/publication/221345737_Rectified_Linear_Units_Improve_Restricted_Boltzmann_Machines_Vinod_Nair", "https://www.researchgate.net/publication/230554866_Discrete-Time_Signal_Processing", "https://www.researchgate.net/publication/259399919_How_to_Construct_Deep_Recurrent_Neural_Networks", "https://www.researchgate.net/publication/261153442_Deep_convolutional_neural_networks_for_LVCSR", "https://www.researchgate.net/publication/260062490_Long_Short-Term_Memory_Based_Recurrent_Neural_Network_Architectures_for_Large_Vocabulary_Speech_Recognition", "https://www.researchgate.net/publication/287364898_Unfolded_recurrent_neural_networks_for_speech_recognition", "https://www.researchgate.net/publication/262030045_Deep_Learning_in_Neural_Networks_An_Overview", "https://www.researchgate.net/publication/3316656_Bidirectional_recurrent_neural_networks", "https://www.researchgate.net/publication/256745020_On_the_Computational_Power_of_Neural_Nets", "https://www.researchgate.net/publication/261193556_Error_back_propagation_for_sequence_training_of_Context-Dependent_Deep_NetworkS_for_conversational_speech_transcription", "https://www.researchgate.net/publication/263564119_DeepFace_Closing_the_Gap_to_Human-Level_Performance_in_Face_Verification", "https://www.researchgate.net/publication/265469170_Recurrent_Neural_Network_Regularization", "https://www.researchgate.net/publication/271855798_Hybrid_Orthogonal_Projection_and_Estimation_HOPE_A_New_Framework_to_Probe_and_Learn_Neural_Networks", "https://www.researchgate.net/publication/282120052_The_New_HOPE_Way_to_Learn_Neural_Networks", "https://www.researchgate.net/publication/282790216_Feedforward_Sequential_Memory_Neural_Networks_without_Recurrent_Feedback", "https://www.researchgate.net/publication/282016681_Rectified_Linear_Neural_Networks_with_Tied-Scalar_Regularization_for_LVCSR", "https://www.researchgate.net/publication/283659606_The_fixed-size_ordinally-forgetting_encoding_method_for_neural_network_language_models"]}