{"cited_in": ["https://www.researchgate.net/publication/283986647_Basic_Level_Categorizatiandon_is_Important_Modelling_the_Facilitation_in_Visual_Object_Recognition"], "datas": {"publication_uid": "280158083", "title": "Experience Matters: Modeling the Relationship Between Face and Object Recognition", "authors": {"1": "Panqu Wang", "3": "Garrison W. Cottrell", "2": "Isabel Gauthier"}, "abstract": "Some research has suggested that face and object recognition are independent abilities. Recently, however, it has been shown that they are not, and that the relationship is moderated by experience with the object categories (Gauthier et al., in press). Gauthier et al. suggest that a domain general ability underlies face and object recognition that is expressed when people have sufficient experience in that category. Using the Cam-bridge Face Memory Test (CFMT) and Vanderbilt Expertise Test (VET), they showed that as experience with non-face object categories grows (averaged over all eight categories of the VET), the shared variance between the CFMT and VET performance increased monotonically. This theory fits with our neu-rocomputational model (\" The Model \" , TM, Cottrell and Hsiao (2011)), since in TM, categories differentiated at the subordinate level are recruited by the face network (Tong, Joyce, & Cottrell, 2008). We model \" domain general ability \" as the resources available for the mapping from images to labels (the number of hidden units), and \" experience \" as the number of training epochs with non-face objects. We show that, as in the data, the shared variance between the performance on faces and the performance on subordinate-level object categoriza-tion increases as experience grows. Our results thus suggest that a potential source for the variance in the \" domain general ability \" between individuals is the amount of representational resources available for fine-level discrimination. One might have expected that faces and objects compete for this shared resource, leading to a negative correlation between them. Our analysis of the hidden unit representations shows that they share a \" spreading \" transform, that moves similar objects apart in representational space, consistent with our previous analyses suggesting that this is why the the Fusiform Face Area is recruited by new categories of expertise (Tong et al., 2008)."}, "references": ["https://www.researchgate.net/publication/10832699_Organization_of_Face_and_Object_Recognition_in_Modular_Neural_Network_Models", "https://www.researchgate.net/publication/10978419_EMPATH_A_neural_network_that_categorizes_facial_expressions", "https://www.researchgate.net/publication/19140456_Daugman_JG_Uncertainty_relation_for_resolution_in_space_spatial_frequency_and_orientation_optimized_by_two-dimensional_visual_cortical_filters_J_Opt_Soc_Am_A_Opt_Image_Sci_Vis_27_1160-1169", "https://www.researchgate.net/publication/51731177_The_Cambridge_Car_Memory_Test_A_task_matched_in_format_to_the_Cambridge_Face_Memory_Test_with_norms_reliability_sex_differences_dissociations_from_face_memory_and_expertise_effects", "https://www.researchgate.net/publication/7593331_The_Cambridge_Face_Memory_Test_Results_for_neurologically_intact_individuals_and_an_investigation_of_its_validity_using_inverted_face_stimuli_and_prosopagnosic_subjects", "https://www.researchgate.net/publication/263742665_Experience_moderates_overlap_between_object_and_face_recognition_suggesting_a_common_ability", "https://www.researchgate.net/publication/31941471_Gauthier_I_Skudlarski_P_Gore_JC_Anderson_AW_Expertise_for_cars_and_birds_recruits_brain_areas_involved_in_face_recognition_Nat_Neurosci_3_191-197", "https://www.researchgate.net/publication/12852048_Activation_of_the_middle_fusiform_'face_area'_increases_with_expertise_in_recognizing_novel_objects", "https://www.researchgate.net/publication/14066306_The_Fusiform_Face_Area_A_Module_in_Human_Extrastriate_Cortex_Specialized_for_Face_Perception", "https://www.researchgate.net/publication/243782020_Distortion_invariant_object_recognition_in_the_dynamik_link_architecture", "https://www.researchgate.net/publication/266632357_Plant_Leaf_Classification_using_Probabilistic_Integration_of_Shape_Texture_and_Margin_Features", "https://www.researchgate.net/publication/231742590_High-resolution_imaging_of_expertise_reveals_reliable_object_selectivity_in_the_FFA_related_to_perceptual_performance", "https://www.researchgate.net/publication/230644581_The_Vanderbilt_Expertise_Test_reveals_domain-general_and_domain-specific_sex_effects_in_object_recognition", "https://www.researchgate.net/publication/233970483_Pose_Estimation_for_Category_Specific_Multiview_Object_Localization", "https://www.researchgate.net/publication/222464584_Optimal_Unsupervised_Learning_in_a_Single-Layer_Linear_Feedforward_Neural_Network", "https://www.researchgate.net/publication/5886949_Why_is_the_fusiform_face_area_recruited_for_novel_categories_of_expertise_A_neurocomputational_investigation", "https://www.researchgate.net/publication/26328081_The_NimStim_set_of_facial_expressions_Judgments_from_untrained_research_participants", "https://www.researchgate.net/publication/7318320_A_Cortical_Region_Consisting_Entirely_of_Face-Selective_Cells", "https://www.researchgate.net/publication/221259620_Learning_Models_for_Object_Recognition_From_Natural_Language_Descriptions", "https://www.researchgate.net/publication/41532354_From_the_Cover_Human_face_recognition_ability_is_specific_and_highly_heritable"]}