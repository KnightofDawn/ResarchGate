{"cited_in": ["https://www.researchgate.net/publication/281144264_A_Deep_Bag-of-Features_Model_for_Music_Auto-Tagging", "https://www.researchgate.net/publication/275347034_A_Deep_Neural_Network_for_Modeling_Music", "https://www.researchgate.net/publication/272787135_Unsupervised_Feature_Learning_for_Urban_Sound_Classification", "https://www.researchgate.net/publication/270292367_Domain-Size_Pooling_in_Local_Descriptors_DSP-SIFT", "https://www.researchgate.net/publication/269294910_Improving_music_auto-tagging_by_intra-song_instance_bagging", "https://www.researchgate.net/publication/259367570_Codebook-Based_Audio_Feature_Representation_for_Music_Information_Retrieval", "https://www.researchgate.net/publication/261277198_Towards_a_more_efficient_sparse_coding_based_audio-word_feature_extraction_system", "https://www.researchgate.net/publication/267801007_Learning_sparse_feature_representations_for_music_annotation_and_retrieval", "https://www.researchgate.net/publication/267961463_Unsupervised_learning_of_local_features_for_music_classification", "https://www.researchgate.net/publication/267784981_Multivariate_autoregressive_mixture_models_for_music_auto-tagging", "https://www.researchgate.net/publication/254462631_Supervised_dictionary_learning_for_music_genre_classification", "https://www.researchgate.net/publication/261266935_Stacked_calibration_of_off-policy_policy_evaluation_for_video_game_matchmaking", "https://www.researchgate.net/publication/270780040_Learning_Deep_Physiological_Models_of_Affect", "https://www.researchgate.net/publication/240308775_Representation_Learning_A_Review_and_New_Perspectives", "https://www.researchgate.net/publication/260721122_A_Bag_of_Systems_Representation_for_Music_Auto-Tagging", "https://www.researchgate.net/publication/262165643_Combining_modality_specific_deep_neural_networks_for_emotion_recognition_in_video", "https://www.researchgate.net/publication/263609596_A_Semantic_Matching_Energy_Function_for_Learning_with_Multi-relational_Data", "https://www.researchgate.net/publication/260439422_Sequential_Complexity_as_a_Descriptor_for_Musical_Similarity", "https://www.researchgate.net/publication/261324918_A_Deep_Representation_for_Invariance_And_Music_Classification", "https://www.researchgate.net/publication/269295463_Improved_music_feature_learning_with_deep_neural_networks", "https://www.researchgate.net/publication/264006806_A_Systematic_Evaluation_of_the_Bag-of-Frames_Representation_for_Music_Information_Retrieval", "https://www.researchgate.net/publication/282984064_Optical_strain_based_recognition_of_subtle_emotions", "https://www.researchgate.net/publication/273327803_EmoNets_Multimodal_deep_learning_approaches_for_emotion_recognition_in_video", "https://www.researchgate.net/publication/280220055_One_hundred_ways_to_process_time_frequency_rate_and_scale_in_the_central_auditory_system_A_pattern-recognition_meta-analysis", "https://www.researchgate.net/publication/282811601_Automatic_Subgrouping_of_Multitrack_Audio", "https://www.researchgate.net/publication/291421871_Detecting_fingering_of_overblown_flute_sound_using_sparse_feature_learning"], "datas": {"publication_uid": "220723342", "title": "Temporal Pooling and Multiscale Learning for Automatic Annotation and Ranking of Music Audio.", "authors": {"1": "Philippe Hamel", "4": "Douglas Eck", "3": "Y. Bengio", "2": "Simon Lemieux"}, "abstract": "  ABSTRACT This paper analyzes some of the challenges in performing automatic annotation and ranking of music audio, and proposes a few improvements. First, we motivate the use of principal component analysis on the mel-scaled spectrum. Secondly, we present an analysis of the impact of the selection of pooling functions for summarization of the features over time. We show that combining several pooling functions improves the performance of the system. Finally, we introduce the idea of multiscale learning. By incorporating these ideas in our model, we obtained state-of-the-art performance on the Magnatagatune dataset.  "}, "references": ["https://www.researchgate.net/publication/224440997_On_the_Use_of_Anti-Word_Models_for_Audio_Music_Annotation_and_Retrieval", "https://www.researchgate.net/publication/216792879_Backpropagation_Applied_to_Handwritten_Zip_Code_Recognition", "https://www.researchgate.net/publication/215991023_Learning_Deep_Architectures_for_AI", "https://www.researchgate.net/publication/3968978_Music_type_classification_by_spectral_contrast_feature", "https://www.researchgate.net/publication/221345753_A_Theoretical_Analysis_of_Feature_Pooling_in_Visual_Recognition", "https://www.researchgate.net/publication/216792737_Scaling_learning_algorithms_towards_AI", "https://www.researchgate.net/publication/220723593_Evaluation_of_Algorithms_Using_Games_The_Case_of_Music_Tagging", "https://www.researchgate.net/publication/221515148_Input-agreement_A_New_Mechanism_for_Collecting_Data_Using_Human_Computation_Games", "https://www.researchgate.net/publication/221223026_Content-based_music_genre_classification_using_timbral_feature_vectors_and_support_vector_machine", "https://www.researchgate.net/publication/242536948_MIREX_SPECIAL_TAGATUNE_EVALUATION_SUBMISSION", "https://www.researchgate.net/publication/220723290_A_Music_Classification_Method_based_on_Timbral_Features", "https://www.researchgate.net/publication/220723272_Learning_Features_from_Music_Audio_with_Deep_Belief_Networks", "https://www.researchgate.net/publication/228542053_MARSYAS_submissions_to_MIREX_2009", "https://www.researchgate.net/publication/220722937_Multiple-Instance_Learning_for_Music_Information_Retrieval", "https://www.researchgate.net/publication/221619818_Unsupervised_feature_learning_for_audio_classification_using_convolutional_deep_belief_networks", "https://www.researchgate.net/publication/220723009_Scalable_Genre_and_Tag_Prediction_with_Spectral_Covariance", "https://www.researchgate.net/publication/289715520_Automatic_tagging_of_audio_The_state-of-the-art"]}