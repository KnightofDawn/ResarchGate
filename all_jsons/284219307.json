{"cited_in": [], "datas": {"publication_uid": "284219307", "title": "From Pose to Activity: Surveying Datasets and Introducing CONVERSE", "authors": {"1": "Michael Edwards", "3": "Xianghua Xie", "2": "Jingjing Deng"}, "abstract": "We present a review on the current state of publicly available datasets within the human action recognition community; highlighting the revival of pose based methods and recent progress of understanding person-person interaction modeling. We categorize datasets regarding several key properties for usage as a benchmark dataset; including the number of class labels, ground truths provided, and application domain they occupy. We also consider the level of abstraction of each dataset; grouping those that present actions, interactions and higher level semantic activities. The survey identifies key appearance and pose based datasets, noting a tendency for simplistic, emphasized, or scripted action classes that are often readily definable by a stable collection of sub-action gestures. There is a clear lack of datasets that provide closely related actions, those that are not implicitly identified via a series of poses and gestures, but rather a dynamic set of interactions. We therefore propose a novel dataset that represents complex conversational interactions between two individuals via 3D pose. 8 pairwise interactions describing 7 separate conversation based scenarios were collected using two Kinect depth sensors. The intention is to provide events that are constructed from numerous primitive actions, interactions and motions, over a period of time; providing a set of subtle action classes that are more representative of the real world, and a challenge to currently developed recognition methodologies. We believe this is among one of the first datasets devoted to conversational interaction classification using 3D pose features and the attributed papers show this task is indeed possible. The full dataset is made publicly available to the research community at www.csvision.swansea.ac.uk/converse."}, "references": ["https://www.researchgate.net/publication/221111664_HMDB51_A_Large_Video_Database_for_Human_Motion_Recognition", "https://www.researchgate.net/publication/233815759_UCF101_A_Dataset_of_101_Human_Actions_Classes_From_Videos_in_The_Wild", "https://www.researchgate.net/publication/4090526_Recognizing_human_actions_A_local_SVM_approach", "https://www.researchgate.net/publication/5911536_Actions_as_Space-Time_Shapes", "https://www.researchgate.net/publication/224165257_Action_recognition_based_on_a_bag_of_3D_points", "https://www.researchgate.net/publication/262274828_Learning_Human_Interaction_by_Interactive_Phrases", "https://www.researchgate.net/publication/275073404_Efficient_Interaction_Recognition_through_Positive_Action_Representation", "https://www.researchgate.net/publication/261283562_Mining_Actionlet_Ensemble_for_Action_Recognition_with_Depth_Cameras", "https://www.researchgate.net/publication/224135256_The_TUM_Kitchen_Data_Set_of_everyday_manipulation_activities_for_motion_tracking_and_action_recognition", "https://www.researchgate.net/publication/51914487_Unstructured_Human_Activity_Detection_from_RGBD_Images", "https://www.researchgate.net/publication/231609161_Learning_Human_Activities_and_Object_Affordances_from_RGB-D_Videos", "https://www.researchgate.net/publication/24248191_View-Independent_Behavior_Analysis", "https://www.researchgate.net/publication/259161444_A_bag_of_words_approach_to_subject_specific_3D_human_pose_interaction_classification_with_random_decision_forests", "https://www.researchgate.net/publication/4308247_ETISEO_performance_evaluation_for_video_surveillance_systems", "https://www.researchgate.net/publication/221361842_Learning_realistic_human_actions_from_movies_In_IEEE_CVPR", "https://www.researchgate.net/publication/259193278_Hollywood_3D_Recognizing_Actions_in_3D_Natural_Scenes", "https://www.researchgate.net/publication/220659514_HumanEva_Synchronized_Video_and_Motion_Capture_Dataset_and_Baseline_Algorithm_for_Evaluation_of_Articulated_Human_Motion", "https://www.researchgate.net/publication/258896444_Free_Viewpoint_Action_Recognition_Using_Motion_History_Volumes", "https://www.researchgate.net/publication/278155069_Evaluation_of_video_activity_localizations_integrating_quality_and_quantity_measurements", "https://www.researchgate.net/publication/221361786_Multisensor-Fusion_for_3D_Full-Body_Human_Motion_Capture", "https://www.researchgate.net/publication/262310813_Analyzing_and_Evaluating_Markerless_Motion_Tracking_Using_Inertial_Sensors", "https://www.researchgate.net/publication/261283554_A_database_for_fine_grained_activity_detection_of_cooking_activities_In_IEEE_CVPR", "https://www.researchgate.net/publication/49853604_Discriminative_Video_Pattern_Search_for_Efficient_Action_Detection", "https://www.researchgate.net/publication/261335265_A_real_time_system_for_dynamic_hand_gesture_recognition_with_a_depth_sensor", "https://www.researchgate.net/publication/224181554_MuHAVi_A_Multicamera_Human_Action_Video_Dataset_for_the_Evaluation_of_Action_Recognition_Methods", "https://www.researchgate.net/publication/221304534_Modeling_Temporal_Structure_of_Decomposable_Motion_Segments_for_Activity_Classification", "https://www.researchgate.net/publication/221292604_The_POETICON_enacted_scenario_corpus_-_A_tool_for_human_and_computational_experiments_on_action_understanding", "https://www.researchgate.net/publication/261421354_Two-person_interaction_detection_using_body-pose_features_and_multiple_instance_learning", "https://www.researchgate.net/publication/221111619_Human_action_recognition_by_learning_bases_of_action_attributes_and_parts", "https://www.researchgate.net/publication/221362695_Action_MACH_a_spatio-temporal_Maximum_Average_Correlation_Height_filter_for_action_recognition", "https://www.researchgate.net/publication/268289684_Utrecht_Multi-Person_Motion_UMPM_benchmark", "https://www.researchgate.net/publication/221477855_ViHASi_Virtual_human_action_silhouette_data_for_the_performance_evaluation_of_silhouette-based_action_recognition_methods", "https://www.researchgate.net/publication/221361825_A_Large-scale_Benchmark_Dataset_for_Event_Recognition_in_Surveillance_Video", "https://www.researchgate.net/publication/272661723_Real-Time_Recognition_of_Action_Sequences_Using_a_DistributedVideo_Sensor_Network", "https://www.researchgate.net/publication/242653265_Enhanced_Computer_Vision_With_Microsoft_Kinect_Sensor_A_Review", "https://www.researchgate.net/publication/4023039_View_invariants_for_human_action_recognition", "https://www.researchgate.net/publication/232297472_An_Efficient_Approach_for_Multi-view_Human_Action_Recognition_Based_on_Bag-of-Key-Poses", "https://www.researchgate.net/publication/261350684_Audio-based_human_activity_recognition_using_Non-Markovian_Ensemble_Voting", "https://www.researchgate.net/publication/5582107_Detection_of_Daily_Activities_and_Sports_With_Wearable_Sensors_in_Controlled_and_Uncontrolled_Conditions", "https://www.researchgate.net/publication/252064077_Macro-class_selection_for_hierarchical_k-nn_classification_of_inertial_sensor_data", "https://www.researchgate.net/publication/224135905_Activity_recognition_using_the_velocity_histories_of_tracked_keypoints_In_IEEE_ICCV", "https://www.researchgate.net/publication/221110370_Efficient_Regression_of_General-Activity_Human_Poses_from_Depth_Images", "https://www.researchgate.net/publication/261334217_Exemplar-based_human_action_pose_correction_and_tagging", "https://www.researchgate.net/publication/239527061_The_Vitruvian_Manifold_Inferring_Dense_Correspondences_for_One-Shot_Human_Pose_Estimation", "https://www.researchgate.net/publication/262159300_Social_interactions_A_first-person_perspective", "https://www.researchgate.net/publication/256091258_Evolutionary_Joint_Selection_to_Improve_Human_Action_Recognition_with_RGB-D_devices", "https://www.researchgate.net/publication/4210181_Behavior_recognition_via_sparse_spatio-temporal_features", "https://www.researchgate.net/publication/224135904_Action_detection_in_complex_scenes_with_spatial_and_temporal_ambiguities_In_IEEE_ICCV", "https://www.researchgate.net/publication/221573131_A_3-dimensional_SIFT_descriptor_and_its_application_to_action_recognition", "https://www.researchgate.net/publication/226678977_On_space-time_interest_points_IJCV", "https://www.researchgate.net/publication/234796092_Topic_and_speaker_identification_via_large_vocabulary_continuous_speech_recognition", "https://www.researchgate.net/publication/31044025_Dialogue_Speech_Recognition_by_Combining_Hierarchical_Topic_Classification_and_Language_Model_Switching", "https://www.researchgate.net/publication/222431291_Emotional_speech_recognition_Resources_features_and_methods", "https://www.researchgate.net/publication/221533537_SVM_with_entropy_regularization_and_particle_swarm_optimization_for_identifying_children's_health_and_socioeconomic_determinants_of_education_attainments_using_linked_datasets"]}