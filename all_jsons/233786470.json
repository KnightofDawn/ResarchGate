{"cited_in": ["https://www.researchgate.net/publication/291336244_RGB-D-based_Action_Recognition_Datasets_A_Survey", "https://www.researchgate.net/publication/283090976_A_Real-Time_Human_Action_Recognition_System_Using_Depth_and_Inertial_Sensor_Fusion", "https://www.researchgate.net/publication/282158094_Action_Recognition_by_using_kernels_on_aclets_sequences", "https://www.researchgate.net/publication/281345013_Human_action_recognition_using_an_improved_string_edit_distance", "https://www.researchgate.net/publication/272029094_Factored_Four_Way_Conditional_Restricted_Boltzmann_Machines_for_Activity_Recognition", "https://www.researchgate.net/publication/267027457_Improving_Human_Action_Recognition_Using_Fusion_of_Depth_Camera_and_Inertial_Sensors", "https://www.researchgate.net/publication/265167543_HAcK_A_System_for_the_Recognition_of_Human_Actions_by_Kernels_of_Visual_Strings", "https://www.researchgate.net/publication/265167470_Exploiting_the_Deep_Learning_Paradigm_for_Recognizing_Human_Actions", "https://www.researchgate.net/publication/280112028_Online_segmentation_and_classification_of_modeled_actions_performed_in_the_context_of_unmodeled_ones", "https://www.researchgate.net/publication/273161846_Human_Activity_Recognition_Process_Using_3-D_Posture_Data", "https://www.researchgate.net/publication/262364315_Towards_Understanding_Action_Recognition", "https://www.researchgate.net/publication/286624308_An_evaluation_of_3D_motion_flow_and_3D_pose_estimation_for_human_action_recognition", "https://www.researchgate.net/publication/257929438_Recognizing_Human_Actions_by_a_Bag_of_Visual_Words", "https://www.researchgate.net/publication/261468406_Fusing_Spatiotemporal_Features_and_Joints_for_3D_Action_Recognition", "https://www.researchgate.net/publication/261468106_Bio-inspired_Dynamic_3D_Discriminative_Skeletal_Features_for_Human_Action_Recognition", "https://www.researchgate.net/publication/238951495_Classifying_and_Visualizing_Motion_Capture_Sequences_using_Deep_Neural_Networks", "https://www.researchgate.net/publication/259172566_3D_flow_estimation_for_human_action_recognition_from_colored_point_clouds", "https://www.researchgate.net/publication/257929296_Recognition_of_Human_Actions_from_RGB-D_Videos_Using_a_Reject_Option", "https://www.researchgate.net/publication/262247832_Subject_independent_human_action_recognition_using_spatio-depth_information_and_meta-cognitive_RBF_network", "https://www.researchgate.net/publication/271462761_Real-time_human_action_recognition_from_motion_capture_data", "https://www.researchgate.net/publication/262329029_Online_RGB-D_gesture_recognition_with_extreme_learning_machines", "https://www.researchgate.net/publication/262324878_Sequence_of_the_most_informative_joints_SMIJ_A_new_representation_for_human_skeletal_action_recognition", "https://www.researchgate.net/publication/271732513_Tracking_the_articulated_motion_of_the_human_body_with_two_RGBD_cameras", "https://www.researchgate.net/publication/286455621_One-Shot_Person_Re-Identification_with_a_Consumer_Depth_Camera", "https://www.researchgate.net/publication/286624208_3D_Reconstruction_of_freely_moving_persons_for_re-identification_with_a_depth_sensor", "https://www.researchgate.net/publication/270583565_Non-rigid_Point_Set_Registration_with_Global-Local_Topology_Preservation", "https://www.researchgate.net/publication/264312484_A_discussion_on_the_validation_tests_employed_to_compare_human_action_recognition_methods_using_the_MSR_Action3D_dataset", "https://www.researchgate.net/publication/264050546_Action_recognition_on_motion_capture_data_using_a_dynemes_and_forward_differences_representation", "https://www.researchgate.net/publication/271484195_Multiscale_integral_invariant_for_motion_trajectory_matching_and_recognition", "https://www.researchgate.net/publication/266838683_Combining_unsupervised_learning_and_discrimination_for_3D_action_recognition", "https://www.researchgate.net/publication/264980346_Gesture_Recognition_Corpora_and_Tools_A_Scripted_Ground_Truthing_Method", "https://www.researchgate.net/publication/279931064_Context_Modulation_of_Sensor_Data_Applied_to_Activity_Recognition_in_Smart_Homes", "https://www.researchgate.net/publication/264005909_Activity-based_methods_for_person_recognition_in_motion_capture_sequences", "https://www.researchgate.net/publication/284281234_Full-body_Pose_Tracking_-_the_Top_View_Reprojection_Approach", "https://www.researchgate.net/publication/270582947_Articulated_Non-Rigid_Point_Set_Registration_for_Human_Pose_Estimation_from_3D_Sensors", "https://www.researchgate.net/publication/264160589_Classifying_actions_based_on_histogram_of_oriented_velocity_vectors", "https://www.researchgate.net/publication/282382543_Human_action_recognition_based_on_mocap_information_using_convolution_neural_networks", "https://www.researchgate.net/publication/273886888_Integral_Invariants_for_space_motion_trajectory_matching_and_recognition", "https://www.researchgate.net/publication/273949412_Recognition_of_human_actions_using_edit_distance_on_aclet_strings", "https://www.researchgate.net/publication/276099585_Multi-layered_multi-exemplar_affinity_propagation_for_temporal_clustering_of_human_motion", "https://www.researchgate.net/publication/275413130_High_dimensional_low_sample_size_activity_recognition_using_geometric_classifiers", "https://www.researchgate.net/publication/276509939_Categorization_of_human_actions_with_high_dynamics_in_upper_extremities_based_on_arm_pose_modeling", "https://www.researchgate.net/publication/285673772_3D_Skeleton-based_Human_Action_Classification_a_Survey", "https://www.researchgate.net/publication/287974349_A_survey_of_depth_and_inertial_sensor_fusion_for_human_action_recognition", "https://www.researchgate.net/publication/283748673_Co-occurrence_Feature_Learning_for_Skeleton_based_Action_Recognition_using_Regularized_Deep_LSTM_Networks"], "datas": {"publication_uid": "233786470", "title": "Berkeley MHAD: A comprehensive Multimodal Human Action Database", "authors": {"1": "Ferda Ofli", "4": "Ren\u00e9 Vidal", "3": "Gregorij Kurillo", "2": "Rizwan Chaudhry", "5": "Ruzena Bajcsy"}, "abstract": "Over the years, a large number of methods have been proposed to analyze human pose and motion information from images, videos, and recently from depth data. Most methods, however, have been evaluated on datasets that were too specific to each application, limited to a particular modality, and more importantly, captured under unknown conditions. To address these issues, we introduce the Berkeley Multimodal Human Action Database (MHAD) consisting of temporally synchronized and geometrically calibrated data from an optical motion capture system, multi-baseline stereo cameras from multiple views, depth sensors, accelerometers and microphones. This controlled multimodal dataset provides researchers an inclusive testbed to develop and benchmark new algorithms across multiple modalities under known capture conditions in various research domains. To demonstrate possible use of MHAD for action recognition, we compare results using the popular Bag-of-Words algorithm adapted to each modality independently with the results of various combinations of modalities using the Multiple Kernel Learning. Our comparative results show that multimodal analysis of human motion yields better action recognition rates than unimodal analysis."}, "references": ["https://www.researchgate.net/publication/4193986_Action_as_space-time_shapes", "https://www.researchgate.net/publication/224165257_Action_recognition_based_on_a_bag_of_3D_points", "https://www.researchgate.net/publication/4301654_Action_Recognition_from_Arbitrary_Views_using_3D_Exemplars", "https://www.researchgate.net/publication/221474944_Segmenting_Motion_Capture_Data_into_Distinct_Behaviors", "https://www.researchgate.net/publication/222543433_A_Survey_of_Computer_Vision-Based_Human_Motion_Capture", "https://www.researchgate.net/publication/220659514_HumanEva_Synchronized_Video_and_Motion_Capture_Dataset_and_Baseline_Algorithm_for_Evaluation_of_Articulated_Human_Motion", "https://www.researchgate.net/publication/227040019_Dataset_Issues_in_Object_Recognition", "https://www.researchgate.net/publication/221429928_RGBD-HuDaAct_a_color-depth_video_database_for_human_daily_activity_recognition_In_IEEE_ICCV_workshop", "https://www.researchgate.net/publication/256979980_A_Survey_of_Vision-Based_Methods_for_Action_Representation_Segmentation_and_Recognition", "https://www.researchgate.net/publication/221110000_On_Feature_Combination_for_Multiclass_Object_Classification", "https://www.researchgate.net/publication/2941192_The_CMU_motion_of_body_MoBo_database", "https://www.researchgate.net/publication/224579268_Recognizing_realistic_actions_from_videos_in_the_Wild", "https://www.researchgate.net/publication/4377099_Integrating_Audio_Visual_Data_for_Human_Action_Detection", "https://www.researchgate.net/publication/224135925_Multiple_Kernels_for_Object_Detection", "https://www.researchgate.net/publication/221304534_Modeling_Temporal_Structure_of_Decomposable_Motion_Segments_for_Activity_Classification", "https://www.researchgate.net/publication/231521391_Documentation_Mocap_database_HDM05", "https://www.researchgate.net/publication/224135256_The_TUM_Kitchen_Data_Set_of_everyday_manipulation_activities_for_motion_tracking_and_action_recognition", "https://www.researchgate.net/publication/220566360_Human_Activity_Analysis_A_Review", "https://www.researchgate.net/publication/261283562_Mining_Actionlet_Ensemble_for_Action_Recognition_with_Depth_Cameras", "https://www.researchgate.net/publication/47863782_Efficient_and_Robust_Annotation_of_Motion_Capture_Data", "https://www.researchgate.net/publication/4038396_Space-time_interest_points", "https://www.researchgate.net/publication/221477855_ViHASi_Virtual_human_action_silhouette_data_for_the_performance_evaluation_of_silhouette-based_action_recognition_methods", "https://www.researchgate.net/publication/221259353_Evaluation_of_Local_Spatio-temporal_Features_for_Action_Recognition", "https://www.researchgate.net/publication/224254745_Unbiased_look_at_dataset_bias", "https://www.researchgate.net/publication/221111664_HMDB51_A_Large_Video_Database_for_Human_Motion_Recognition", "https://www.researchgate.net/publication/221361842_Learning_realistic_human_actions_from_movies_In_IEEE_CVPR", "https://www.researchgate.net/publication/4090526_Recognizing_human_actions_A_local_SVM_approach"]}