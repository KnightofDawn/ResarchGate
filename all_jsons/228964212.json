{"cited_in": ["https://www.researchgate.net/publication/221230398_Analysis_and_Evaluation_of_Learning_Classifier_Systems_applied_to_Hyperspectral_Image_Classification"], "datas": {"publication_uid": "228964212", "title": "Reinforcement Learning using LCS in Continuous State Space IWLCS-2004 Extended Abstract", "authors": {"1": "David Leroux", "2": "Michael L. Littman"}, "abstract": "  ABSTRACT Reinforcement Learning, RL, deals with a class of problems in which a policy is to be learned based solely on numerical reward signals that are often significantly delayed from when the actions are selected. LCS has been shown to be an effective method for RL, but most of the applications have been in discrete state space. The more commonly used approaches within RL, e.g., policy search, value iteration, and Q-learning, have also generally been applied to discrete state space, although a number of techniques have been proposed recently for extending traditional techniques to continuous state space problems. This paper looks at how LCS might be used for such problems. A basic LCS technique is developed and applied to a commonly studied RL problem to demonstrate that an accurate value function and policy may be learned in time comparable to techniques used in traditional RL approaches. The LCS method proposed is kept minimal and an evaluation test-bed is suggested so that enhancements to the LCS methodology may be evaluated to determine which enhancements provide the greatest benefit. A number of suggestions are made for future study of such enhancements.  "}, "references": ["https://www.researchgate.net/publication/2240187_Practical_Reinforcement_Learning_in_Continuous_Domains", "https://www.researchgate.net/publication/221620522_Generalization_in_Reinforcement_Learning_Safely_Approximating_the_Value_Function", "https://www.researchgate.net/publication/2600802_Delayed_Reinforcement_Fuzzy_Q-Learning_and_Fuzzy_Logic_Controllers", "https://www.researchgate.net/publication/225891365_Locally_weighted_learning_AI_Rev", "https://www.researchgate.net/publication/220814096_Variable_Resolution_Discretization_for_High-Accuracy_Solutions_of_Optimal_Control_Problems", "https://www.researchgate.net/publication/2625587_Practical_Reinforcement_Learning_in_Continuous_Spaces", "https://www.researchgate.net/publication/236027647_An_Introduction_to_Reinforcement_Learning", "https://www.researchgate.net/publication/235709806_Reinforcement_Learning_A_Survey", "https://www.researchgate.net/publication/2612701_Stable_Function_Approximation_in_Dynamic_Programming", "https://www.researchgate.net/publication/220423062_Temporal_Difference_Learning_and_TD-Gammon", "https://www.researchgate.net/publication/220343680_Toward_a_Model_of_Intelligence_as_an_Economy_of_Agents", "https://www.researchgate.net/publication/221345670_Residual_Algorithms_Reinforcement_Learning_with_Function_Approximation", "https://www.researchgate.net/publication/245586584_Generalization_in_Reinforcement_Learning_Safely_Approximating_theValue_Function", "https://www.researchgate.net/publication/2817307_Classifier_Fitness_Based_on_Accuracy", "https://www.researchgate.net/publication/2817318_State_of_XCS_Classifier_System_Research", "https://www.researchgate.net/publication/2668096_Reinforcement_Learning_with_Perceptual_Aliasing_The_Perceptual_Distinctions_Approach", "https://www.researchgate.net/publication/2518821_Get_Real_XCS_with_Continuous-Valued_Inputs"]}