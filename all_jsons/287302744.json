{"cited_in": [], "datas": {"publication_uid": "287302744", "title": "Ada-boosting Extreme learning machines for handwritten digit and digit strings recognition", "authors": {"1": "Raid Saabni"}, "abstract": "  ABSTRACT Automatic handwriting recognition of digit strings, is of academic and commercial interest. Current algorithms are already quite good at learning to recognize handwritten digits, which enables to use them for sorting letters and reading personal checks. Neural networks are a powerful technology for classification of visual inputs arising from documents, and have been extensively used in many fields due to their ability to approximate complex nonlinear mappings directly from the input sample. Different variations of Multi-Layer Neural Networks (MLNN), using back propagation training algorithm, yield a very high recognition rates on handwritten digits benchmarks, but lacks the aspect of speed in training time. Learning time is an important factor while designing any computational intelligent algorithm for classifications, especially when online improving by adapting new samples is needed. Extreme Learning Machine (ELM) has been proposed as an alternative ANN, which significantly reduce the amount of time needed to train a MLNN and has been widely used for many applications. The ELM analytical process of learning reduces the time of learning comparing to back propagation by avoiding the process of iterative learning. In this paper, we present a process which boosts few Extreme learning machines using Ada-boosting in order to improve the recognition rates iteratively. A pre-processing step is used to improve the ability of the ELM, and special weighting process to improve the boosting process. To evaluate the presented approach, we have used the (HDRC 2013) data-set which have bee used at the 2014 competition on handwritten digit string recognition organized in conjunction with ICFHR2014 of Western Arabic digit string recognition with varying length. Very high accurate results in terms of very low error rates while keeping efficient time of online training were achieved by the presented approach, which enables on demand time/precision tradeoff.  "}, "references": ["https://www.researchgate.net/publication/244890032_A_statistical--topological_feature_combination_for_recognition_of_handwritten_numerals", "https://www.researchgate.net/publication/2924845_Training_Invariant_Support_Vector_Machines", "https://www.researchgate.net/publication/2806398_Boosting_a_Weak_Learning_Algorithm_By_Majority", "https://www.researchgate.net/publication/225070191_A_Decision-Theoretic_Generalization_of_On-Line_Learning_and_an_Application_to_Boosting", "https://www.researchgate.net/publication/6928613_Universal_Approximation_Using_Incremental_Constructive_Feedforward_Networks_With_Random_Hidden_Nodes", "https://www.researchgate.net/publication/4116697_Extreme_learning_machine_A_new_learning_scheme_of_feedforward_neural_networks", "https://www.researchgate.net/publication/222667300_Extreme_Learning_Machine_Theory_and_Applications", "https://www.researchgate.net/publication/222523132_A_trainable_feature_extractor_for_handwritten_digit_recognition", "https://www.researchgate.net/publication/247931959_The_mnist_database_of_handwritten_digits", "https://www.researchgate.net/publication/224716259_Unsupervised_Learning_of_Invariant_Feature_Hierarchies_with_Applications_to_Object_Recognition", "https://www.researchgate.net/publication/216792739_Efficient_Learning_of_Sparse_Representations_with_an_Energy-Based_Model", "https://www.researchgate.net/publication/220320616_Learning_a_Nonlinear_Embedding_by_Preserving_Class_Neighbourhood_Structure", "https://www.researchgate.net/publication/272832134_The_Strength_of_Weak_Learnability", "https://www.researchgate.net/publication/220860992_Best_Practices_for_Convolutional_Neural_Networks_Applied_to_Visual_Document_Analysis", "https://www.researchgate.net/publication/2985446_Gradient-based_learning_applied_to_document_recognition_Proc_IEEE"]}